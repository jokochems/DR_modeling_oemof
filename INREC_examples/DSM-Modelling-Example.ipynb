{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling demand response: comparison of modelling approaches\n",
    "\n",
    "This notebook contains a comparison of Demand Response modelling approaches. In the following, the terms Demand Response (DR) and Demand Side Management (DSM) are used interchangeably. The focus is on load shifting, but load shedding is included in the model formulations compared as well.\n",
    "\n",
    "## Purpose and background\n",
    "\n",
    "* This notebook is based on an implementation of Julian Endres created within the wind note project, see: https://github.com/windnode/SinkDSM_example/blob/master/DSM-Modelling.ipynb\n",
    "* It's main purpose is to compare different implementations for demand response modelling.\n",
    "* The modelling approaches considered are the following ones:\n",
    "    * Zerrahn & Schill (2015)\n",
    "    * Steurer (2017)\n",
    "    * Gils (2015)\n",
    "    * Ladwig (2018)\n",
    "\n",
    "## Method\n",
    "\n",
    "To compare the modelling approaches, the following methodology is applied:\n",
    "1. A simple toy model is set up.\n",
    "    * There is one backup generation unit and one serving average demand at no marginal costs.\n",
    "    * DSM units are defined to be a low variable costs option.\n",
    "    * The parameterization for DSM units is harmonized as far as this is possible for the different modelling approaches in order to isolate effects which are based on different DSM implementations.\n",
    "2. Different cases are depicted using the toy model in order to compare different DR modelling approaches:\n",
    "    * Case 1: Simple demand variation\n",
    "    * Case 2: Demand variations\n",
    "        * 2a: variations with the same amplitude each\n",
    "        * 2b: variations with a changing amplitude\n",
    "        * 2c: variations with changed starting timesteps for load shifts\n",
    "        * 2d: variations with a longer duration (shift for several subsequent hours)\n",
    "        * 2e: variations demanding for longer shift times\n",
    "    * Case 3: Increase in demand (use case for load shedding)\n",
    "    * Case 4: (asymmetric) variations in generation and constant demand\n",
    "    * Case 4: variations in demand and generation \n",
    "3. Different parameter variations and optional constraints are analyzed, comprising the following:\n",
    "    * variations in delay time, i.e. shifting time\n",
    "    * variations in shift time, i.e. interference time\n",
    "    * variations in DSM costs\n",
    "    * variations in DSM efficiency\n",
    "    * variations in recovery time resp. maximum activations\n",
    "        * basic comparison\n",
    "        * changed demand pattern for comparison\n",
    "        * separate comparison of short term limits imposed\n",
    "    * variations in the amoung of daily activations\n",
    "    * analysis of additional constraint imposing an overall DSM capacity limit\n",
    "4. Benchmarks concerning the following elements are carried out\n",
    "    * objective value\n",
    "    * runtime\n",
    "\n",
    "In addition to the very stylized toy model, a more realistic example model is considered as well and other stylized examples are added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Imports and plot settings\n",
    "Imports:\n",
    "* Standard imports\n",
    "* Import the different implementations for demand response components\n",
    "* Import module `plotting.py` for extracting results and visualization\n",
    "\n",
    "Plot settings:<br>\n",
    "* Register matplotlib converters.\n",
    "* Adjust matplotlib standard settings for graphs.\n",
    "* Create a directory to store graphs (if it doesn't already exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import oemof.solph as solph\n",
    "from oemof.network.network import Node\n",
    "\n",
    "# Import the different alternative implementations\n",
    "import oemof_SinkDSM as DSM_DIW\n",
    "import oemof_DR_component_DLR_naming_adjusted as DSM_DLR\n",
    "import oemof_DR_component_DLR_naming_adjusted_shifting_classes as DSM_DLR_ShiftClass\n",
    "import oemof_DR_component_DLR_naming_adjusted_no_shed as DSM_DLR_NoShed\n",
    "import oemof_DR_component_IER_naming_adjusted as DSM_IER\n",
    "import oemof_DR_component_TUD_naming_adjusted as DSM_TUD\n",
    "\n",
    "# Import module for plotting (results handling)\n",
    "import plotting as plt_dsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine matplotlib settings\n",
    "register_matplotlib_converters()\n",
    "\n",
    "SMALL_SIZE = 13\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## base dataset\n",
    "plt_dsm.make_directory('graphics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter settings\n",
    "* General parameter settings for controlling the notebooks workflow\n",
    "* Special parameter settings for DSM parameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameter settings\n",
    "Control **workflow** of notebook:\n",
    "* *performance_benchmark*: If True, model performance will be evaluated for the different approaches.<br> &rarr; _Note: Since this is quite computation intense, it should be deactivated if it is not the special interest._\n",
    "* *target_benchmark*: If True, the target function values for the different modelling approaches will be compared.\n",
    "* *save_figs*: If True, all figures will be saved in the graphics folder.\n",
    "* *save_results*: If True, overall amounts of demand response activations will be saved to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to control overall workflow\n",
    "performance_benchmark = False\n",
    "target_benchmark = False\n",
    "save_figs = True\n",
    "save_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSM parameter settings\n",
    "Define major **parameters concerning demand response modelling**\n",
    "* *aproaches*: List of the approaches used for demand response modelling\n",
    "* *addition*: Boolean parameter indicating, whether or not to include an additional \"logic\" constraint into the other DSM modelling approaches that is similar to equation 10 of Zerrahn & Schill (2015)\n",
    "* *efficiency*: Consider a pontential efficiency loss for those modelling approaches which depict DSM efficiency (all except for Ladwig 2018).\n",
    "* *recovery_time*: Consider a pontential recovery time for those modelling approaches which depict it (only Zerrahn & Schill 2015).\n",
    "* *ActivateYearLimit*: Boolean variable indicating whether or not to use a limit for DSM activations per year (only applicable for Gils 2015).\n",
    "* *ActivateDayLimit*: Boolean variable indicating whether or not to use a limit for DSM activations per day resp. per rolling window (only applicable for Gils 2015).\n",
    "\n",
    "Determine **costs for demand response**:\n",
    "* *include_costs*: If True, (small) variable costs will be included.\n",
    "* *cost_dsm*: Overall variable costs for demand response which have to be splitted up to up and downwards shifts\n",
    "* *cost_dsm_up*: Costs for upwards shifts (_defaults to have of the overall costs_)\n",
    "* *cost_dsm_down*: Costs for downwards shifts (_defaults to have of the overall costs_)\n",
    "\n",
    "Introduce special control variables for controlling the **workflow**, especially for approach from DLR (Gils 2015):\n",
    "* *introduce_second_dsm_unit*: If True, a second demand response unit with the same parameterization will be introduced.\n",
    "* *few_timesteps*: If True, for the simple example the timeset will be limited to 9 timesteps in order to increase readability of the .lp-files\n",
    "* *use_shifting_classes*: If True, shifting classes will be applied in the approach from DLR (Gils 2015)\n",
    "* *use_no_shed*: If True, the approach from DLR (Gils 2015) withouth a load shedding implementation will be utilized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters focussing on demand response modelling\n",
    "approaches = [\"DIW\", \"DLR\", \"IER\", \"TUD\"]\n",
    "addition = False\n",
    "efficiency = 1\n",
    "recovery_time = None\n",
    "ActivateYearLimit = False\n",
    "ActivateDayLimit = False\n",
    "\n",
    "# Determine cost consideration\n",
    "include_costs = True\n",
    "\n",
    "if include_costs:\n",
    "    cost_dsm = 0.1\n",
    "\n",
    "else:\n",
    "    cost_dsm = 0\n",
    "\n",
    "# Cost is split half on upwards and downwards shift; shedding gets high costs\n",
    "cost_dsm_up = cost_dsm/2\n",
    "cost_dsm_down_shift = cost_dsm/2\n",
    "cost_dsm_down_shed = 1000 * cost_dsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables for demand response modelling\n",
    "introduce_second_dsm_unit = False\n",
    "few_timesteps = True\n",
    "\n",
    "# Define whether or not to use the shifting classes approach for DLR (Gils 2015) -> not working yet!\n",
    "use_no_shed = False\n",
    "use_shifting_classes = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools for setup, results extraction and visualization of a (toy) energy system model\n",
    "For the testing, a **toy energy system** is set up including:\n",
    "- Coal PP\n",
    "- Wind PP\n",
    "- PV PP\n",
    "- DSM Sink\n",
    "- shortage\n",
    "- excess\n",
    "\n",
    "**Rules for DSM parametrization**:\n",
    "\n",
    "The following rules apply for parameters which are not part of every modelling approach:<br>\n",
    "* shift (resp. interference) times: These will be defined half of the delay time and symmetrical in the first place.\n",
    "* additional parameters: These will be defined to be not bounding in the first place.\n",
    "* optional parameters & constraints: These will be ignored in the first place.\n",
    "* additional constraints: These will also be ignored in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and solve the model\n",
    "A function is defined here for setting up and solving the toy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data, datetimeindex, directory, project, approach,\n",
    "                 delay_time, shed_time, cost_dsm_up, cost_dsm_down_shift, \n",
    "                 cost_dsm_down_shed, efficiency,\n",
    "                 shed_eligibility, shift_eligibility, introduce_second_dsm_unit,\n",
    "                 **kwargs):\n",
    "    \"\"\" Function to create and solve the model. \"\"\"\n",
    "    \n",
    "    # Control generation units\n",
    "    include_coal = kwargs.get('include_coal', True)\n",
    "    include_gas = kwargs.get('include_gas', False)\n",
    "    nom_cap_coal = kwargs.get('nom_cap_coal', 10000)\n",
    "    nom_cap_gas = kwargs.get('nom_cap_gas', 10000)\n",
    "    nom_cap_pv = kwargs.get('nom_cap_pv', 1)\n",
    "    \n",
    "    # Special kwargs for DSM modelling (one approach only)\n",
    "    method = kwargs.get('method', 'delay')\n",
    "    shift_interval = kwargs.get('shift_interval', 24)\n",
    "    recovery_time_shift = kwargs.get('recovery_time_shift', None)\n",
    "    recovery_time_shed = kwargs.get('recovery_time_shed', 24)\n",
    "    use_no_shed = kwargs.get('use_no_shed', False)\n",
    "    use_shifting_classes = kwargs.get('use_shifting_classes', False)\n",
    "    shift_time = kwargs.get('shift_time', delay_time/2)\n",
    "    start_times = kwargs.get('start_times', [1])\n",
    "    \n",
    "    addition = kwargs.get('addition', False)\n",
    "    fixes = kwargs.get('fixes', False)\n",
    "    \n",
    "    ActivateYearLimit = kwargs.get('ActivateYearLimit', False)\n",
    "    ActivateDayLimit = kwargs.get('ActivateDayLimit', False)\n",
    "\n",
    "    # ----------------- Energy System ----------------------------\n",
    "    \n",
    "    # Create Energy System\n",
    "    es = solph.EnergySystem(timeindex=datetimeindex)\n",
    "                           #groupings=[type])\n",
    "    len_data = len(data.loc[datetimeindex,:])    \n",
    "    \n",
    "    Node.registry = es\n",
    "\n",
    "    # Create Buses\n",
    "    if include_coal:\n",
    "        b_coal_1 = solph.Bus(label='bus_coal_1')\n",
    "    if include_gas:\n",
    "        b_gas_1 = solph.Bus(label='bus_gas_1')\n",
    "    b_elec = solph.Bus(label='bus_elec')\n",
    "\n",
    "    # Create Sources\n",
    "    if include_coal:\n",
    "        s_coal_p1 = solph.Source(label='source_coal_p1',\n",
    "                                 outputs={\n",
    "                                    b_coal_1: solph.Flow(\n",
    "                                        nominal_value=nom_cap_coal,\n",
    "                                        variable_costs=13)}\n",
    "                                 )\n",
    "    if include_gas:\n",
    "        s_gas_p1 = solph.Source(label='source_gas_p1',\n",
    "                                 outputs={\n",
    "                                    b_gas_1: solph.Flow(\n",
    "                                        nominal_value=nom_cap_gas,\n",
    "                                        variable_costs=25)}\n",
    "                                 )        \n",
    "\n",
    "    s_wind = solph.Source(label='wind',\n",
    "                          outputs={\n",
    "                              b_elec: solph.Flow(\n",
    "                                  fix=data['wind'][datetimeindex],\n",
    "                                  nominal_value=1)}\n",
    "                          )\n",
    "\n",
    "    s_pv = solph.Source(label='pv',\n",
    "                        outputs={\n",
    "                            b_elec: solph.Flow(\n",
    "                                fix=data['pv'][datetimeindex],\n",
    "                                nominal_value=nom_cap_pv)}\n",
    "                        )\n",
    "\n",
    "    # Create Transformers\n",
    "    if include_coal:\n",
    "        cfp_1 = solph.Transformer(label='pp_coal_1',\n",
    "                                  inputs={b_coal_1: solph.Flow()},\n",
    "                                  outputs={\n",
    "                                      b_elec: solph.Flow(\n",
    "                                          variable_costs=0)},\n",
    "                                  conversion_factors={b_elec: 0.4}\n",
    "                                  )\n",
    "    if include_gas:\n",
    "        gfp_1 = solph.Transformer(label='pp_gas_1',\n",
    "                                  inputs={b_gas_1: solph.Flow()},\n",
    "                                  outputs={\n",
    "                                      b_elec: solph.Flow(\n",
    "                                          variable_costs=0)},\n",
    "                                  conversion_factors={b_elec: 0.4}\n",
    "                                  )\n",
    "    \n",
    "    # Create DSM units\n",
    "\n",
    "    # Define kwargs that are identical for all DSM units\n",
    "    kwargs_all = {'label': 'demand_dsm',\n",
    "                  'inputs': {b_elec: solph.Flow(variable_costs=0)},\n",
    "                  'demand': data['demand_el'][datetimeindex],\n",
    "                  'capacity_up': data['Cap_up'][datetimeindex],\n",
    "                  'capacity_down': data['Cap_do'][datetimeindex],\n",
    "                  'delay_time': delay_time,\n",
    "                  'shed_time': shed_time,\n",
    "                  'recovery_time_shift': recovery_time_shift,\n",
    "                  'recovery_time_shed': recovery_time_shed,\n",
    "                  'cost_dsm_up': cost_dsm_up,\n",
    "                  'cost_dsm_down_shift': cost_dsm_down_shift,\n",
    "                  'cost_dsm_down_shed': cost_dsm_down_shed,\n",
    "                  'efficiency': efficiency,\n",
    "                  'shed_eligibility': shed_eligibility,\n",
    "                  'shift_eligibility': shift_eligibility}\n",
    "    \n",
    "    # Define kwargs that differ dependent on approach chosen\n",
    "    \n",
    "    # Determine recovery / max activations / cumulative shift / shed time dependent on each other\n",
    "    if recovery_time_shift is not None:\n",
    "        n_yearLimit_shift = kwargs.get('n_yearLimit_shift', \n",
    "                                       len_data // (delay_time + recovery_time_shift))\n",
    "        daily_frequency_shift = kwargs.get('daily_frequency_shift', \n",
    "                                           24 // (delay_time + recovery_time_shift))\n",
    "    else:\n",
    "        n_yearLimit_shift = kwargs.get('n_yearLimit_shift', \n",
    "                                       len_data // delay_time)\n",
    "        daily_frequency_shift = kwargs.get('daily_frequency_shift', \n",
    "                                           24 // delay_time)\n",
    "    \n",
    "    if recovery_time_shed is not None:\n",
    "        n_yearLimit_shed = kwargs.get('n_yearLimit_shed', \n",
    "                                      len_data // (shed_time + recovery_time_shed))\n",
    "    else:\n",
    "        n_yearLimit_shed = kwargs.get('n_yearLimit_shed', \n",
    "                                      len_data // shed_time)\n",
    "    \n",
    "    cumulative_shift_time = n_yearLimit_shift * shift_time\n",
    "    cumulative_shed_time = n_yearLimit_shed * shed_time\n",
    "    \n",
    "    if not daily_frequency_shift == 0:\n",
    "        t_dayLimit = kwargs.get('t_dayLimit', \n",
    "                                24 / daily_frequency_shift - 1)\n",
    "    else:\n",
    "        t_dayLimit = kwargs.get('t_dayLimit', 0) \n",
    "\n",
    "    kwargs_dict = {\n",
    "        'DIW': {'method': method,\n",
    "                'shift_interval': shift_interval},\n",
    "                   \n",
    "        'IER': {'shift_time_up': shift_time,\n",
    "                'shift_time_down': shift_time,\n",
    "                'start_times': start_times,\n",
    "                'cumulative_shift_time': cumulative_shift_time,\n",
    "                'cumulative_shed_time': cumulative_shed_time,\n",
    "                'addition': addition,\n",
    "                'fixes': fixes},\n",
    "        \n",
    "        'DLR': {'shift_time': shift_time,\n",
    "                'ActivateYearLimit': ActivateYearLimit,\n",
    "                'ActivateDayLimit': ActivateDayLimit,\n",
    "                'n_yearLimit_shift': n_yearLimit_shift,\n",
    "                'n_yearLimit_shed': n_yearLimit_shed,\n",
    "                't_dayLimit': t_dayLimit,\n",
    "                'addition': addition,\n",
    "                'fixes': fixes},\n",
    "        \n",
    "        'TUD': {'shift_time_down': shift_time,\n",
    "                'postpone_time': shift_time,\n",
    "                'annual_frequency_shift': n_yearLimit_shift,\n",
    "                'annual_frequency_shed': n_yearLimit_shed,\n",
    "                'daily_frequency_shift': daily_frequency_shift,\n",
    "                'addition': addition}\n",
    "                  }\n",
    "    \n",
    "    # Optionally attribute half of the potential to a second identical dsm unit with a new label\n",
    "    if introduce_second_dsm_unit:\n",
    "        kwargs_all['demand'] = kwargs_all['demand']/2\n",
    "        kwargs_all['capacity_up'] = kwargs_all['capacity_up']/2\n",
    "        kwargs_all['capacity_down'] = kwargs_all['capacity_down']/2\n",
    "        \n",
    "        # Copy data and drop label as well as inputs since these cause trouble otherwise\n",
    "        kwargs_all_manipulated = kwargs_all.copy()\n",
    "        kwargs_all_manipulated.pop('label')\n",
    "        kwargs_all_manipulated.pop('inputs')\n",
    "    \n",
    "    # Actually build the units\n",
    "    if approach == \"DIW\":\n",
    "        demand_dsm = DSM_DIW.SinkDSM(**kwargs_all,\n",
    "                                     **kwargs_dict[approach])\n",
    "        \n",
    "        if introduce_second_dsm_unit:\n",
    "            demand_dsm2 = DSM_DIW.SinkDSM(label=\"demand_dsm2\",\n",
    "                                          inputs={b_elec: solph.Flow(variable_costs=0)},\n",
    "                                          **kwargs_all_manipulated,\n",
    "                                          **kwargs_dict[approach]\n",
    "                                    )\n",
    "        \n",
    "    elif approach == \"IER\":\n",
    "        demand_dsm = DSM_IER.SinkDSI(**kwargs_all,\n",
    "                                     **kwargs_dict[approach])\n",
    "        \n",
    "        if introduce_second_dsm_unit:\n",
    "            demand_dsm2 = DSM_IER.SinkDSI(label=\"demand_dsm2\",\n",
    "                                          inputs={b_elec: solph.Flow(variable_costs=0)},\n",
    "                                          **kwargs_all_manipulated,\n",
    "                                          **kwargs_dict[approach])\n",
    "    \n",
    "    elif approach == \"DLR\":   \n",
    "        # Use approach without shifing classes but with shedding\n",
    "        if not (use_no_shed or use_shifting_classes):\n",
    "            demand_dsm = DSM_DLR.SinkDR(**kwargs_all,\n",
    "                                        **kwargs_dict[approach])\n",
    "            \n",
    "            if introduce_second_dsm_unit:\n",
    "                demand_dsm2 = DSM_DLR.SinkDR(label=\"demand_dsm2\",\n",
    "                                             inputs={b_elec: solph.Flow(variable_costs=0)},\n",
    "                                             **kwargs_all_manipulated,\n",
    "                                             **kwargs_dict[approach])\n",
    "        \n",
    "        # Use approach without shedding (and without shifting classes)\n",
    "        elif use_no_shed:\n",
    "            demand_dsm = DSM_DLR_NoShed.SinkDR(**kwargs_all,\n",
    "                                               **kwargs_dict[approach])\n",
    "\n",
    "            if introduce_second_dsm_unit:\n",
    "                demand_dsm2 = DSM_DLR_NoShed.SinkDR(label=\"demand_dsm2\",\n",
    "                                                    inputs={b_elec: solph.Flow(variable_costs=0)},\n",
    "                                                    **kwargs_all_manipulated,\n",
    "                                                    **kwargs_dict[approach])\n",
    "        \n",
    "        # Use approach with shifting classes\n",
    "        else:\n",
    "            demand_dsm = DSM_DLR_ShiftClass.SinkDR(**kwargs_all,\n",
    "                                                    **kwargs_dict[approach])\n",
    "            \n",
    "            if introduce_second_dsm_unit:\n",
    "                demand_dsm2 = DSM_DLR_ShiftClass.SinkDR(label=\"demand_dsm2\",\n",
    "                                                        inputs={b_elec: solph.Flow(variable_costs=0)},\n",
    "                                                        **kwargs_all_manipulated,\n",
    "                                                        **kwargs_dict[approach])\n",
    "\n",
    "    elif approach == \"TUD\":\n",
    "        demand_dsm = DSM_TUD.SinkDSM(**kwargs_all,\n",
    "                                     **kwargs_dict[approach])\n",
    "\n",
    "        if introduce_second_dsm_unit:\n",
    "            demand_dsm2 = DSM_TUD.SinkDSM(label=\"demand_dsm2\",\n",
    "                                          inputs={b_elec: solph.Flow(variable_costs=0)},\n",
    "                                          **kwargs_all_manipulated,\n",
    "                                          **kwargs_dict[approach])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"No valid value for approach. Must be one of ['DIW', 'IER', 'DLR', 'TUD']\")\n",
    "\n",
    "    # Backup excess / shortage\n",
    "    excess = solph.Sink(label='excess_el',\n",
    "                        inputs={b_elec: solph.Flow(variable_costs=1)}\n",
    "                        )\n",
    "\n",
    "    s_shortage_el = solph.Source(label='shortage_el',\n",
    "                                 outputs={\n",
    "                                     b_elec: solph.Flow(\n",
    "                                         variable_costs=200)}\n",
    "                                 )\n",
    "\n",
    "    # -------------------------- Create Model ----------------------\n",
    "    \n",
    "    #pprint.pprint(es.groups, width=1)\n",
    "    \n",
    "    # Create Model\n",
    "    model = solph.Model(es)\n",
    "\n",
    "    # Solve Model\n",
    "    model.solve(solver='gurobi', solve_kwargs={'tee': False})\n",
    "\n",
    "    # Write LP File\n",
    "    filename = os.path.join(os.path.dirname('__file__'), directory, project +'.lp')\n",
    "    model.write(filename, io_options={'symbolic_solver_labels': True})\n",
    "\n",
    "    # Save Results\n",
    "    es.results['main'] = solph.processing.results(model)\n",
    "    es.results['meta'] = solph.processing.meta_results(model)\n",
    "    es.dump(dpath=None, filename=None)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model results and plot the model\n",
    "A function is defined here to extract results from the model and plot the model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_model(df_data, timesteps, **kwargs):\n",
    "    \"\"\" Function to extract model results and plot the model. \"\"\"\n",
    "    \n",
    "    approach = kwargs.get('approach', 'DIW')\n",
    "    \n",
    "    # Control plotting and processing\n",
    "    case = kwargs.get('case', 'constant')\n",
    "    param_variations = kwargs.get('param_variations', '')\n",
    "    plot = kwargs.get('plot', False)\n",
    "    figure_size = kwargs.get('figsize', (15, 10))\n",
    "    legend = kwargs.get(\"legend\", False)\n",
    "    show = kwargs.get('show', False)\n",
    "    save = kwargs.get('save', False),\n",
    "    ax1_ylim = kwargs.get('ax1_ylim', [-10, 210])\n",
    "    ax2_ylim = kwargs.get('ax2_ylim', [-110, 110])\n",
    "    include_generators = kwargs.get('include_generators', False)\n",
    "    \n",
    "    # Control generation units\n",
    "    gen_dict = {'include_coal': kwargs.get('include_coal', True),\n",
    "                'include_gas': kwargs.get('include_gas', False),\n",
    "                'nom_cap_coal': kwargs.get('nom_cap_coal', 10000),\n",
    "                'nom_cap_gas': kwargs.get('nom_cap_gas', 10000),\n",
    "                'nom_cap_pv': kwargs.get('nom_cap_pv', 1)}\n",
    "    \n",
    "    # ----------------- Input Data & Timesteps ----------------------------\n",
    "\n",
    "    # Provide directory\n",
    "    project = 'demand_shift_' + approach + '_' + case + param_variations\n",
    "    directory = './'\n",
    "\n",
    "    # Data manipulation\n",
    "    data = df_data\n",
    "\n",
    "    # Timestamp\n",
    "    datetimeindex = pd.date_range(start='1/1/2013',\n",
    "                                  periods=timesteps,\n",
    "                                  freq='H')\n",
    "    \n",
    "    len_data = len(data.loc[datetimeindex,:])\n",
    "    \n",
    "    # ----------------- DSM Parameterization ----------------------------\n",
    "    \n",
    "    introduce_second_dsm_unit = kwargs.get('introduce_second_dsm_unit', False)\n",
    "    \n",
    "    # kwargs for all approaches\n",
    "    delay_time = kwargs.get('delay_time', 1)\n",
    "    shed_time = kwargs.get('shed_time', 1)\n",
    "    cost_dsm_up = kwargs.get('cost_dsm_up', 0)\n",
    "    cost_dsm_down_shift = kwargs.get('cost_dsm_down_shift', 0)\n",
    "    cost_dsm_down_shed = kwargs.get('cost_dsm_down_shed', 0)\n",
    "    efficiency = kwargs.get('efficiency', 1)\n",
    "    shed_eligibility = kwargs.get('shed_eligibility', False)\n",
    "    shift_eligibility = kwargs.get('shift_eligibility', True)\n",
    "    \n",
    "    # kwargs that differ dependent on approach chosen\n",
    "    shift_time = kwargs.get('shift_time', delay_time/2)\n",
    "    start_times = kwargs.get('start_times', [1])\n",
    "    \n",
    "    # determine recovery / max activations / cumulative shift / shed time dependent on each other\n",
    "    recovery_time_shift = kwargs.get('recovery_time_shift', None)\n",
    "    recovery_time_shed = kwargs.get('recovery_time_shed', 24)\n",
    "    \n",
    "    if recovery_time_shift is not None:\n",
    "        n_yearLimit_shift = kwargs.get('n_yearLimit_shift', \n",
    "                                       len_data // (delay_time + recovery_time_shift))\n",
    "        daily_frequency_shift = kwargs.get('daily_frequency_shift', \n",
    "                                           24 // (delay_time + recovery_time_shift))\n",
    "    else:\n",
    "        n_yearLimit_shift = kwargs.get('n_yearLimit_shift', \n",
    "                                       len_data // delay_time)\n",
    "        daily_frequency_shift = kwargs.get('daily_frequency_shift',\n",
    "                                           24 // delay_time)\n",
    "   \n",
    "    if recovery_time_shed is not None:\n",
    "        n_yearLimit_shed = kwargs.get('n_yearLimit_shed', \n",
    "                                      len_data // (shed_time + recovery_time_shed))\n",
    "    else:\n",
    "        n_yearLimit_shed = kwargs.get('n_yearLimit_shed', \n",
    "                                      len_data // shed_time)\n",
    "    \n",
    "    cumulative_shift_time = n_yearLimit_shift * shift_time\n",
    "    cumulative_shed_time = n_yearLimit_shed * shed_time\n",
    "\n",
    "    if not daily_frequency_shift == 0:\n",
    "        t_dayLimit = kwargs.get('t_dayLimit', \n",
    "                                24 / daily_frequency_shift - 1)\n",
    "    else:\n",
    "        t_dayLimit = kwargs.get('t_dayLimit', 0) \n",
    "    \n",
    "    kwargs_dict = {\n",
    "        'oemof': {'method': kwargs.get('method', None),\n",
    "                'shift_interval': kwargs.get('shift_interval', None)},\n",
    "\n",
    "        'DIW': {'method': kwargs.get('method', None),\n",
    "                'shift_interval': kwargs.get('shift_interval', None)},\n",
    "                   \n",
    "        'IER': {'shift_time_up': shift_time,\n",
    "                'shift_time_down': shift_time,\n",
    "                'start_times': start_times,\n",
    "                'cumulative_shift_time': cumulative_shift_time,\n",
    "                'cumulative_shed_time': cumulative_shed_time,\n",
    "                'addition': kwargs.get('addition', False),\n",
    "                'fixes': kwargs.get('fixes', False)},\n",
    "        \n",
    "        'DLR': {'shift_time': shift_time,\n",
    "                'ActivateYearLimit': kwargs.get('ActivateYearLimit', False),\n",
    "                'ActivateDayLimit': kwargs.get('ActivateDayLimit', False),\n",
    "                'n_yearLimit_shift': n_yearLimit_shift,\n",
    "                'n_yearLimit_shed': n_yearLimit_shed,\n",
    "                't_dayLimit': t_dayLimit,\n",
    "                'addition': kwargs.get('addition', False),\n",
    "                'fixes': kwargs.get('fixes', False)},\n",
    "        \n",
    "        'TUD': {'shift_time_down': shift_time,\n",
    "                'postpone_time': shift_time,\n",
    "                'annual_frequency_shift': n_yearLimit_shift,\n",
    "                'annual_frequency_shed': n_yearLimit_shed,\n",
    "                'daily_frequency_shift': daily_frequency_shift,\n",
    "                'addition': kwargs.get('addition', False)}              \n",
    "                  }   \n",
    "\n",
    "    # Introduce another dict for controlling the approaches workflows\n",
    "    # So far, these only apply for DLR approach (might be removed later on)\n",
    "    control_dict = {\n",
    "        'oemof':{},\n",
    "        'DIW':{},\n",
    "        'IER':{},\n",
    "        'DLR':{'use_no_shed': kwargs.get('use_no_shed', True),\n",
    "               'use_shifting_classes': kwargs.get('use_shifting_classes', False)},\n",
    "        'TUD':{}      \n",
    "    }\n",
    "    \n",
    "    # ----------------- Create & Solve Model ----------------------------\n",
    "\n",
    "    # Create model\n",
    "    model = create_model(data,\n",
    "                         datetimeindex, \n",
    "                         directory, \n",
    "                         project,\n",
    "                         approach,\n",
    "                         delay_time, \n",
    "                         shed_time,\n",
    "                         cost_dsm_up, \n",
    "                         cost_dsm_down_shift,\n",
    "                         cost_dsm_down_shed,\n",
    "                         efficiency,\n",
    "                         shed_eligibility,\n",
    "                         shift_eligibility,\n",
    "                         introduce_second_dsm_unit,\n",
    "                         recovery_time_shift=recovery_time_shift,\n",
    "                         recovery_time_shed=recovery_time_shed,\n",
    "                         **kwargs_dict[approach],\n",
    "                         **control_dict[approach],\n",
    "                         **gen_dict)\n",
    "    \n",
    "    #model.pprint()\n",
    "\n",
    "    # Get Results\n",
    "    es = solph.EnergySystem()\n",
    "    es.restore(dpath=None, filename=None)\n",
    "    \n",
    "    results = es.results['main']\n",
    "    meta = es.results['meta']\n",
    "    \n",
    "    # Export data\n",
    "    df_gesamt = plt_dsm.extract_results(model, approach, **control_dict[approach], **gen_dict)\n",
    "    #display(df_gesamt)\n",
    "    \n",
    "    # write data to csv\n",
    "    #df_gesamt.to_csv(directory + project + '_data_dump.csv')\n",
    "    \n",
    "    # ----------------- Plot Results ----------------------------\n",
    "    if plot:\n",
    "        plt_dsm.plot_dsm(\n",
    "            df_gesamt,\n",
    "            directory,\n",
    "            project,\n",
    "            **control_dict[approach],\n",
    "            days=2,\n",
    "            show=show,\n",
    "            figsize=figure_size,\n",
    "            ax1_ylim=ax1_ylim,\n",
    "            ax2_ylim=ax2_ylim,\n",
    "            include_generators=include_generators,\n",
    "            approach=approach,\n",
    "            legend=legend,\n",
    "            save=save\n",
    "        )\n",
    "    \n",
    "    return df_gesamt, model, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot case (availability and generation data)\n",
    "Function to visualize the case considered for the simple example model\n",
    "* Show availability, i.e. capacity bounds for DSM\n",
    "* Show demand before DSM and generation pattern as well as \"residual load\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case(data, case='constant', **kwargs):\n",
    "    \"\"\" Function to plot the case considered.\n",
    "    \n",
    "    Case is defined by availability time series, i.e. capacity bounds for DSM and\n",
    "    demand before DSM as well as generation pattern.\n",
    "    \"\"\"\n",
    "    show = kwargs.get('show', True)\n",
    "    save_figs = kwargs.get('save_figs', True)\n",
    "    \n",
    "    # Plot demand, wind generation and DR capacity limits\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    _ = plt.title('Erzeugung und Last für Fall: \"' + case + '\"')\n",
    "\n",
    "    # Define xaxis ticks\n",
    "    # ax.xaxis_date()\n",
    "    # ax.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m - %H h'))  # ('%d.%m-%H h'))\n",
    "    # ax.set_xlim(data.index.values[0] - pd.Timedelta(1, 'h'), \n",
    "    #             data.index.values[0] + pd.Timedelta(1, 'h'))\n",
    "    # plt.xticks(pd.date_range(start=data.index.values[0], \n",
    "    #                          periods=len(data)+1, \n",
    "    #                          freq='H'), rotation=90)\n",
    "    data_reindexed = data.reset_index(drop=True)\n",
    "    data_reindexed[\"new_index\"] = list(range(1, len(data) + 1))\n",
    "    data_reindexed.set_index(\"new_index\", drop=True, inplace=True)\n",
    "    plt.xticks(range(1, len(data) + 1), rotation=90)\n",
    "    \n",
    "    ax.plot(data_reindexed.index, data_reindexed['demand_el'].values, drawstyle=\"steps-post\", label=\"Nachfrage\")\n",
    "    ax.plot(data_reindexed.index, data_reindexed['wind'].values, drawstyle=\"steps-post\", label=\"Erzeugung\")\n",
    "\n",
    "    # Cap_up and Cap_do only included for proper alignment here\n",
    "    ax.plot(data_reindexed.index, (data_reindexed['demand_el'] + data_reindexed['Cap_up']).values, \n",
    "            drawstyle=\"steps-post\", color=\"limegreen\", label=\"oberes Limit\")\n",
    "    ax.plot(data_reindexed.index, (data_reindexed['demand_el'] - data_reindexed['Cap_do']).values, \n",
    "            drawstyle=\"steps-post\", color=\"lightcoral\", label=\"unteres Limit\")\n",
    "    \n",
    "    _ = ax.set_yticks(range(-(data_reindexed.Cap_do.max()-100), data_reindexed.Cap_up.max()+125, 25))\n",
    "    # ax.legend(bbox_to_anchor=(0., -0.35, 1., 0.102), loc=2, ncol=2, borderaxespad=0.)\n",
    "    _ = ax.set_xlabel(\"Zeit in h\", labelpad=10)\n",
    "    _ = ax.set_ylabel(\"Leistung in MW \\n(Nachfrage, Erzeugung, abs. Limits)\", labelpad=10)\n",
    "\n",
    "    plt.grid(alpha=0.6)\n",
    "    \n",
    "    # Delta MW on secondary y_axis\n",
    "    ax2 = ax.twinx()\n",
    "    #ax2.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m - %H h'))  # ('%d.%m-%H h'))\n",
    "    #ax2.set_xlim(data.index.values[0] - pd.Timedelta(1, 'h'), \n",
    "    #            data.index.values[-1] + pd.Timedelta(1, 'h'))\n",
    "    #plt.xticks(pd.date_range(start=data.index.values[0], \n",
    "    #                         periods=len(data)+1, \n",
    "    #                         freq='H'), rotation=90)\n",
    "\n",
    "    ax2.plot(data_reindexed.index, data_reindexed.Cap_up.values, drawstyle=\"steps-post\", #secondary_y=True, \n",
    "             linestyle=\":\", color=\"darkgreen\", label=\"verfügbare Kapazität für Lasterhöhung (rechte Achse)\")\n",
    "    ax2.plot(data_reindexed.index, (data_reindexed.Cap_do*-1).values, drawstyle=\"steps-post\", #secondary_y=True, \n",
    "             linestyle=\":\", color=\"saddlebrown\", label=\"verfügbare Kapazität für Lastreduktion (rechte Achse)\")\n",
    "    \n",
    "    _ = ax2.set_yticks(range(-data_reindexed.Cap_do.max(), data_reindexed.Cap_up.max()+50, 50))\n",
    "    handles, labels = [], []\n",
    "    for ax_object in [ax, ax2]:\n",
    "        h, l = ax_object.get_legend_handles_labels()\n",
    "        handles.extend(h)\n",
    "        labels.extend(l)\n",
    "        \n",
    "    _ = plt.legend(\n",
    "                handles,\n",
    "                labels,\n",
    "                loc=\"upper center\",\n",
    "                bbox_to_anchor=(0, -0.35, 1., 0.102),\n",
    "                fancybox=True,\n",
    "                shadow=False,\n",
    "                ncol=3,\n",
    "            )\n",
    "    # ax2.legend(bbox_to_anchor=(0., -0.35, 1., 0.102), loc=1, ncol=1, borderaxespad=0.)\n",
    "    _ = ax2.set_ylabel(\"Laständerung in MW \\n(Erhöhung, Reduktion)\", labelpad=10)\n",
    "    \n",
    "    # Do axis aligment\n",
    "    plt_dsm.align_yaxis(ax, -(data_reindexed.Cap_do.max()-100), ax2, -data.Cap_do.max())\n",
    "    plt_dsm.align_yaxis(ax, data_reindexed.Cap_up.max()+100, ax2, data.Cap_up.max())\n",
    "    \n",
    "    _ = ax.margins(0, 0.05)\n",
    "    _ = ax2.margins(0, 0.05)\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save_figs:\n",
    "        _ = plt.tight_layout()\n",
    "        name = 'toy-model_' + case + '.png'\n",
    "        fig.savefig('./graphics/' + name, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(name + \" saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case_residual(data, case='constant', **kwargs):\n",
    "    \"\"\" Function to plot the residual load for the respective case. \n",
    "    \n",
    "    Residual load is defined here as the difference between\n",
    "    generic generation and demand, i.e., what is actually to be balanced.\n",
    "    \"\"\"\n",
    "    show = kwargs.get('show', True)\n",
    "    save_figs = kwargs.get('save_figs', True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    _ = plt.title('\"Residual load\" for case \"' + case + '\"')\n",
    "\n",
    "    ax.xaxis_date()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m - %H h'))  # ('%d.%m-%H h'))\n",
    "    ax.set_xlim(data.index.values[0] - pd.Timedelta(1, 'h'), \n",
    "                data.index.values[0] + pd.Timedelta(1, 'h'))\n",
    "    plt.xticks(pd.date_range(start=data.index.values[0], \n",
    "                             periods=len(data)+1, \n",
    "                             freq='H'), rotation=90)\n",
    "\n",
    "    ax.plot(data.index, (data['wind'] - data['demand_el']).values, drawstyle=\"steps-post\", \n",
    "            linestyle=\"-.\", label=\"residual load\", color=\"black\")\n",
    "    _ = ax.set_yticks(range(-100,125,25))\n",
    "    plt.grid()\n",
    "    _ = ax.set_ylabel(\"MW \\n(residual load)\")\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save_figs:\n",
    "        name = 'toy-model_' + case + '_residual.png'\n",
    "        fig.savefig('./graphics/' + name)\n",
    "        plt.close()\n",
    "        print(name + \" saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and display a results table\n",
    "Function to compare the overall results as far as amount of DSM activations, generation and shortage / excess is concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_table(approach_dict, save_results, MultiIndex=False, \n",
    "                       param_name=\"costs\", decimals=0):\n",
    "    \"\"\" Show and visualize the results from the previous model run \"\"\"\n",
    "    # Show total values for the timeframe considered\n",
    "    if not MultiIndex:\n",
    "        dsm = pd.DataFrame()\n",
    "    else:\n",
    "        dsm = pd.DataFrame(columns=pd.MultiIndex.from_tuples(approach_dict.keys()))\n",
    "        dsm.columns.rename([\"approach\", param_name], inplace=True)\n",
    "  \n",
    "    for index, df in approach_dict.items():\n",
    "        dsm[index]  = df[0].abs().sum().round(decimals=decimals)\n",
    "        dsm.loc['gen_total', index] = df[0][['wind', 'pv', 'coal1']].sum().sum().round()\n",
    "        dsm.loc['gen_generic', index] = df[0][['wind', 'pv']].sum().sum().round()\n",
    "\n",
    "    display(dsm.loc[['demand_el','dsm_tot','excess',\n",
    "                     'cap_up', 'cap_do',\n",
    "                     'gen_total','gen_generic',\n",
    "                     'wind', 'pv', 'coal1']].T.style.bar(axis=0 ,color='goldenrod'))\n",
    "\n",
    "    if save_results:\n",
    "        name = 'results_' + case + '.csv'\n",
    "        dsm.loc[['demand_el','dsm_tot','excess',\n",
    "                     'cap_up', 'cap_do',\n",
    "                     'gen_total','gen_generic',\n",
    "                     'wind', 'pv', 'coal1']].T.to_csv('./graphics/' + name, sep=';', decimal=',')\n",
    "        print(name + ' saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model results for realistic toy model\n",
    "A separate function similar to the one above is defined, which is tailored at a more realistic toy model.\n",
    "* A loop over all approaches is directly integrated here.\n",
    "* Results are then added to a dict indexed by approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_realistic_example(data, start_model, timesteps_model, approaches, **kwargs):\n",
    "    \"\"\" Create and solve a more realistic example model. \"\"\"\n",
    "    \n",
    "    dict_df_model = {}\n",
    "    dict_meta_model = {}\n",
    "    \n",
    "    plot = kwargs.get('plot', False)\n",
    "    \n",
    "    directory=\"./\"\n",
    "\n",
    "    # Adjust Timesteps\n",
    "    start_model = pd.to_datetime(start_model, utc=True).tz_convert(tz)\n",
    "\n",
    "    if isinstance(timesteps_model, str):\n",
    "        if timesteps_model == 'all':\n",
    "            timesteps_model_in = data.index[-1]\n",
    "        else:\n",
    "            timesteps_model_in = timesteps_model\n",
    "\n",
    "        datetimeindex = pd.date_range(start=start_model,\n",
    "                                      end=timesteps_model_in, freq='H', tz=tz)\n",
    "\n",
    "    else:\n",
    "        timesteps_model_in = timesteps_model\n",
    "        datetimeindex = pd.date_range(start=start_model,\n",
    "                                      periods=timesteps_model_in, freq='H', tz=tz)\n",
    "    \n",
    "    # ----------------- DSM Parameterization ----------------------------\n",
    "    \n",
    "    introduce_second_dsm_unit = kwargs.get('introduce_second_dsm_unit', False)\n",
    "    \n",
    "    # kwargs for all approaches\n",
    "    delay_time = kwargs.get('delay_time', 1)\n",
    "    shed_time = kwargs.get('shed_time', 1)\n",
    "    cost_dsm_up = kwargs.get('cost_dsm_up', 0)\n",
    "    cost_dsm_down_shift = kwargs.get('cost_dsm_down_shift', 0)\n",
    "    cost_dsm_down_shed = kwargs.get('cost_dsm_down_shed', 0)\n",
    "    efficiency = kwargs.get('efficiency', 1)\n",
    "    shed_eligibility = kwargs.get('shed_eligibility', False)\n",
    "    shift_eligibility = kwargs.get('shift_eligibility', True)\n",
    "    \n",
    "    # kwargs that differ dependent on approach chosen\n",
    "    kwargs_dict = {\n",
    "        'DIW': {'method': kwargs.get('method', None),\n",
    "                'shift_interval': kwargs.get('shift_interval', None),\n",
    "                'recovery_time_shift': kwargs.get('recovery_time_shift', None),\n",
    "                'recovery_time_shed': kwargs.get('recovery_time_shed', 24)},\n",
    "                   \n",
    "        'IER': {'shift_time_up': delay_time/2,\n",
    "                'shift_time_down': delay_time/2,\n",
    "                'start_times': kwargs.get('start_times', [1]),\n",
    "                'cumulative_shift_time': len(data.loc[datetimeindex,:]),\n",
    "                'cumulative_shed_time': len(data.loc[datetimeindex,:]),\n",
    "                'addition': kwargs.get('addition', False),\n",
    "                'fixes': kwargs.get('fixes', False)},\n",
    "        \n",
    "        'DLR': {'shift_time': delay_time/2,\n",
    "                'ActivateYearLimit': kwargs.get('ActivateYearLimit', False),\n",
    "                'ActivateDayLimit': kwargs.get('ActivateDayLimit', False),\n",
    "                'n_yearLimit_shift': kwargs.get('n_yearLimit_shift', 0),\n",
    "                'n_yearLimit_shed': kwargs.get('n_yearLimit_shed', 0),\n",
    "                't_dayLimit': kwargs.get('t_dayLimit', 0),\n",
    "                'addition': kwargs.get('addition', False),\n",
    "                'fixes': kwargs.get('fixes', False)},\n",
    "        \n",
    "        'TUD': {'shift_time_down': delay_time/2,\n",
    "                'postpone_time': delay_time/2,\n",
    "                'annual_frequency_shift': len(data.loc[datetimeindex,:])/delay_time,\n",
    "                'annual_frequency_shed': len(data.loc[datetimeindex,:])/shed_time,\n",
    "                'daily_frequency_shift': 24/delay_time,\n",
    "                'addition': kwargs.get('addition', False)}              \n",
    "                  }\n",
    "    \n",
    "    # Introduce another dict for controlling the approaches workflows\n",
    "    # So far, these only apply for DLR approach (might be removed later on)\n",
    "    control_dict = {\n",
    "        'DIW':{},\n",
    "        'IER':{},\n",
    "        'DLR':{'use_no_shed': kwargs.get('use_no_shed', True),\n",
    "               'use_shifting_classes': kwargs.get('use_shifting_classes', False)},\n",
    "        'TUD':{}      \n",
    "    }\n",
    "\n",
    "    # ----------------- Create & Solve Models ----------------------\n",
    "    \n",
    "    for approach in approaches:\n",
    "        \n",
    "        model = create_model(data,\n",
    "                             datetimeindex,\n",
    "                             directory,\n",
    "                             project,\n",
    "                             approach,\n",
    "                             delay_time, \n",
    "                             shed_time, \n",
    "                             cost_dsm_up, \n",
    "                             cost_dsm_down_shift, \n",
    "                             cost_dsm_down_shed, \n",
    "                             efficiency,\n",
    "                             shed_eligibility, \n",
    "                             shift_eligibility,\n",
    "                             introduce_second_dsm_unit,\n",
    "                             **kwargs_dict[approach],\n",
    "                             **control_dict[approach])\n",
    "        \n",
    "        # Get results\n",
    "        es = solph.EnergySystem()\n",
    "        es.restore(dpath=None, filename=None)\n",
    "        \n",
    "        results = es.results['main']\n",
    "        meta = es.results['meta']\n",
    "        \n",
    "        # Extract data from model\n",
    "        df_model = plt_dsm.extract_results(model, approach, **control_dict[approach])\n",
    "        df_model.index = pd.to_datetime(datetimeindex, utc=True).tz_convert(tz)\n",
    "\n",
    "        # Export data to dict\n",
    "        dict_df_model.update({'{}'.format(approach):df_model})\n",
    "        dict_meta_model.update({'{}'.format(approach):meta})\n",
    "\n",
    "    return dict_df_model, datetimeindex, dict_meta_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw results for more realistic toy model\n",
    "Plot certain columns of the results DataFrame only in order to be able to compare energy on hold, capacity limits etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_results_plot(dict_df_model, start, timesteps, tz, column, negate,\n",
    "                      figure_size, title, ylabel, drawstyle, color, **kwargs):\n",
    "    \"\"\" Functions draws results plots for realistic toy example \"\"\"\n",
    "    \n",
    "    save = kwargs.get('save', False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    ax.set_title(title, fontsize=15)\n",
    "    \n",
    "    keys=[]\n",
    "    for i, (key, df) in enumerate(dict_df_model.items()):\n",
    "        keys.append(key)\n",
    "        if isinstance(column, list):\n",
    "            for col in column:\n",
    "                if not negate[col]:\n",
    "                    df.loc[steps,col].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "                else:\n",
    "                    (df*(-1)).loc[steps,col].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "        else:\n",
    "            if not negate:\n",
    "                df.loc[steps,column].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "            else:\n",
    "                (df*(-1)).loc[steps,column].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(pd.date_range(start=start, periods=timesteps/3, freq='3h', tz=tz))\n",
    "    ax.xaxis.set_major_formatter((mdates.DateFormatter('%H h')))\n",
    "    ax.xaxis.grid(True, which=\"minor\")\n",
    "    ax.xaxis.grid(False, which=\"major\")\n",
    "    ax.hlines(y=0, xmin=start, xmax=end)\n",
    "\n",
    "    handles, _ = ax.get_legend_handles_labels() \n",
    "    if isinstance(column, list):\n",
    "        handles = handles[::len(column)]\n",
    "    labels = ['{}'.format(keys) for keys in keys]\n",
    "\n",
    "    ax.legend(handles, labels, bbox_to_anchor=(0., -.35, 1., .102), loc=3, ncol=2, mode=\"expand\", borderaxespad=0.1, fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    # Provide directory\n",
    "    project = 'demand_shift_' + case\n",
    "    if isinstance(column, list):\n",
    "        for col in column:\n",
    "            project = project + '_' + col\n",
    "    else:\n",
    "        project = project + '_' + column\n",
    "    directory = './'\n",
    "    \n",
    "    if save:\n",
    "        fig.set_tight_layout(True)\n",
    "        name = 'Plot_' + project + '_' + '.png'\n",
    "        fig.savefig(directory + 'graphics/' + name)\n",
    "        plt.close()\n",
    "        print(name + ' saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic comparison for simple setting\n",
    "In the following, the results for the toy model considerations are depicted. This section is structured as follows:\n",
    "* At first a base data set is defined, consisting of a flat demand, a fixed generic generation and capacity limits for DSM.\n",
    "* Then, the demand and/or generic generation the above stated cases are evaluated for the DSM behaviour. The cases are:\n",
    "    * Case 1: Simple demand variation\n",
    "    * Case 2: Demand variations\n",
    "        * 2a: variations with the same amplitude each\n",
    "        * 2b: variations with a changing amplitude\n",
    "        * 2c: variations with changed starting timesteps for load shifts\n",
    "        * 2d: variations with a longer duration (shift for several subsequent hours)\n",
    "        * 2e: variations demanding for longer shift times\n",
    "    * Case 3: Increase in demand (use case for load shedding)\n",
    "    * Case 4: (asymmetric) variations in generation and constant demand\n",
    "    * Case 4: variations in demand and generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine base data set\n",
    "* A basic data set for the toy model is defined in the following.\n",
    "* To analyze different behaviour of the modelling approaches, this data set is modified for the different cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 48\n",
    "\n",
    "# base data set\n",
    "demand = [100] * timesteps\n",
    "pv = [0] * timesteps\n",
    "capup = [100] * timesteps\n",
    "capdo = [100] * timesteps\n",
    "wind = [100] * timesteps\n",
    " \n",
    "base = [demand, wind, capup, capdo, pv]\n",
    "df_base = pd.DataFrame(list(zip(*base)))\n",
    "df_base.rename(columns={0:'demand_el',1:'wind', 2:'Cap_up', 3:'Cap_do', 4:'pv'}, inplace=True)\n",
    "df_base['timestamp'] = pd.date_range(start='1/1/2013', periods=timesteps, freq='H')\n",
    "df_base.set_index('timestamp', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_base, case=\"Basisfall\")\n",
    "plot_case_residual(data=df_base, case=\"base data set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Only one demand variation and constant generation\n",
    "Analyze one of the most simple examples. Slice only a few timesteps to get an easily readable .lp-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Simple Nachfragevariation'\n",
    "\n",
    "# Base data set\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# Manipulate demand\n",
    "demand[1:2] = [150]\n",
    "demand[5:6] = [50]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the first couple of hours to obtain readable .lp files\n",
    "if few_timesteps:\n",
    "    df_data = df_data[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                                          cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, \n",
    "                                          figsize=(15, 8), legend=True, \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          start_times=[1],\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_dict[\"DLR\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Variation in demand and constant generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several cases in which the demand pattern is altered in order to analyze the DSM behaviour. Compared to variations in generation (which are basically interchangeable to demand variations if they happen in the opposite direction), the benefit is that deviations in demand can be easily identified in the results plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2a: Variations in demand (same amplitude) and constant generation\n",
    "Substitute flat demand by introducing two demand peaks and drops each per day with a constant amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Nachfragevariationen mit gleicher Amplitude'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [150]\n",
    "demand[5:6] = [50]\n",
    "\n",
    "demand[11:12] = [150]\n",
    "demand[13:14] = [50]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [50]\n",
    "    demand[29:30] = [150]\n",
    "\n",
    "    demand[36:37] = [50]\n",
    "    demand[40:41] = [150]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(12, 8),   \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          start_times=[4, 11, 26, 36],\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2b: Variations in demand (changing amplitude) and constant generation\n",
    "Substitute flat demand by introducing two demand peaks and drops each per day with a changing, i.e. increasing amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Nachfragevariationen mit unterschiedlicher Amplitude'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [125]\n",
    "demand[5:6] = [75]\n",
    "\n",
    "demand[11:12] = [150]\n",
    "demand[13:14] = [50]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [25]\n",
    "    demand[29:30] = [175]\n",
    "\n",
    "    demand[36:37] = [0]\n",
    "    demand[40:41] = [200]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(12,8),  \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          #start_times=[4, 8, 9, 11, 26, 36],\n",
    "                                          start_times=[4, 11, 26, 36],\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2c: Variations in demand (changing starts) and constant generation\n",
    "Substitute flat demand by introducing two demand peaks and drops each per day with a changing amplitude. In addition to that alter the start of the load shifting processes, since some approaches (esp. TUD) tend to behave very sensitive to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Nachfragevariationen mit veränderten Startzeitpunkten'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[3:4] = [125]\n",
    "demand[4:5] = [75]\n",
    "\n",
    "demand[15:16] = [150]\n",
    "demand[17:18] = [50]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [25]\n",
    "    demand[29:30] = [175]\n",
    "\n",
    "    demand[37:38] = [0]\n",
    "    demand[41:42] = [200]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Note: For this case, an in depth analysis of the starting timesteps used in the IER approach is made._\n",
    "> _There are five possible constellations for this which can be seen with the second demand variation here serving as an example:_\n",
    "> 1. _The starting timestep of the demand variation ($t_A=15$) is met: The fluctuation is properly levelled out._\n",
    "> 2. _Only half of the variation lies within the range from $t_A$ to $t_A + t_{shift}$ ($t_A=12$): The demand response storage level remains unbalanced._\n",
    "> 3. _A starting timestep within a tolerance band around the actual starting timestep is met (here: $t_A=13$): The fluctuation still can be levelled out since balancing until the end of the demand variation ($t=17$) is possible._\n",
    "> 4. _There are two starting timesteps ($t_A=12$ and $t_A=15$) surrounding the actual demand variation: An additional activation is made in order to fulfill the balancing for the first and the last starting timestep._\n",
    "> 5. _Starting timesteps may block the actual activation: This is the case if $t_A=12$, $t_A=13$ and $t_A=16$ have to be met all at the same time._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(12,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          start_times=[3, 15, 26, 36],\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)\n",
    "    \n",
    "    #start_times_dict = {\"unbalanced\": [3, 12, 26, 36],\n",
    "    #                    \"tolerance\": [3, 13, 26, 36],\n",
    "    #                    \"additional\": [3, 12, 15, 26, 36],\n",
    "    #                    \"blocking\": [3, 12, 13, 16, 26, 36]}\n",
    "    # Analyze the effect of different start times\n",
    "    #if approach == \"IER\":\n",
    "    #    for st_key, st_val in start_times_dict.items():\n",
    "    #        approach_dict[approach+\"_\"+st_key] = \\\n",
    "    #            start_model(df_data, timesteps=len(df_data), \n",
    "    #                        plot=True, save=save_figs, case=case, \n",
    "    #                        method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "    #                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "    #                        cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "    #                        addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(12,8),  \n",
    "    #                        shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "    #                        start_times=st_val,\n",
    "    #                        fixes=False,\n",
    "    #                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "    #                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2d: Variations in demand (longer duration) and constant generation\n",
    "Substitute flat demand by introducing in total three demand peaks and drops. The peaks and drops have a longer duration of more than one hour each. Thus, it can be seen how potential limits in interference times (i.e. shift times) behave (for the DLR approach).\n",
    "\n",
    "> _Note: For the DLR approach, it has been noticed that the core formulation can lead to unbalanced shifts at the end.<br> &rarr; Thus, an own fix is introduced forbidding shifts at the end that cannot be compensated for anymore. This is done within the variant with the addition \"\\_fixes\"._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Nachfragevariationen mit längeren Dauern'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[6:8] = [125] * 2\n",
    "demand[8:10] = [75] * 2\n",
    "\n",
    "demand[15:18] = [150] * 3\n",
    "demand[18:21] = [50] * 3\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[34:38] = [25] * 4\n",
    "    demand[38:42] = [175] * 4\n",
    "\n",
    "    #demand[34:36] = [50] * 2\n",
    "    #demand[36:38] = [0] * 2\n",
    "    #demand[38:40] = [150] * 2\n",
    "    #demand[40:42] = [200] * 2\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, \n",
    "                                          save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                                          cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, \n",
    "                                          figsize=(12,8), \n",
    "                                          start_times=[6, 15, 34],\n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)\n",
    "    \n",
    "    if approach in [\"DLR\", \"IER\"]:\n",
    "        approach_dict[approach+\"_fixes\"] = start_model(df_data, timesteps=len(df_data), plot=True, \n",
    "                                      save=save_figs, case=case, \n",
    "                                      method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                      cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                                      cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                      addition=False, fixes=True,\n",
    "                                      recovery_time_shift=None, recovery_time_shed=4, \n",
    "                                      figsize=(12,8), \n",
    "                                      start_times=[6, 15, 34],\n",
    "                                      shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                      introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                      use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2e: Variations in demand (longer shifts) and constant generation\n",
    "Substitute flat demand by introducing in total three demand peaks and drops. The time between the initial process and its balancing opposite is much longer in this example, so some approaches cannot manage to level out the variations (TUD approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Nachfragevariationen mit längerem Verschiebehorizont'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [125]\n",
    "demand[9:10] = [75]\n",
    "\n",
    "demand[19:20] = [150]\n",
    "demand[25:26] = [50]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[34:35] = [25]\n",
    "    demand[41:42] = [175]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(12,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          start_times=[4, 19, 34],\n",
    "                                          fixes=True,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: Increase in demand and constant generation (use case for load shedding)\n",
    "Substitute flat demand by introducing one demand peak over several hours which gives a use case for load shedding. Load shedding costs which are usually very high are set to a lower value here, in order to force some shedding avtivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_shed'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[10:14] = [200] * 4\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _**NOTE:** A much lower value is used here for shedding costs in order to incentivize load shedding._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                                          cost_dsm_down_shed=0.1,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, \n",
    "                                          figsize=(15,8), \n",
    "                                          fixes=True,\n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4: Variations in generation and constant demand\n",
    "Introduce wind peaks and wind drops with a changing amplitude. It can be seen that some approaches are not eligible for levelling out changing amplitudes outside fixed shifting cycles (TUD approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case = 'gen_variation'\n",
    "\n",
    "# Data preperation: manipulate wind data\n",
    "df_data = df_base.copy()\n",
    "wind = [100] * timesteps\n",
    "\n",
    "# wind changes\n",
    "wind[1:2] = [0]\n",
    "wind[4:5] = [175]\n",
    "if timesteps > 24:\n",
    "    wind[41:42] = [200]\n",
    "    wind[44:45] = [25]\n",
    "\n",
    "# Asymmetric shift within shifting cycle possible for TUD\n",
    "#    wind[1:2] = [0]\n",
    "#    wind[2:3] = [175]\n",
    "#    if timesteps > 24:\n",
    "#        wind[4:5] = [200]\n",
    "#        wind[5:6] = [25]\n",
    "\n",
    "df_data['wind'] = wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          start_times=[1, 41],\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 5: Variations in demand and generation\n",
    "Demand and wind variations are introduced. The residual load plot shows what is effectively to be balanced here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'combined_variation'\n",
    "\n",
    "# Data preperation: manipulate demand and wind data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "wind = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[11:12] = [50]\n",
    "demand[13:14] = [150]\n",
    "if timesteps > 24:\n",
    "    demand[33:34] = [150]\n",
    "    demand[37:38] = [50]\n",
    "\n",
    "# wind changes\n",
    "wind[3:4] = [0]\n",
    "wind[10:11] = [175]\n",
    "if timesteps > 24:\n",
    "    wind[38:39] = [200]\n",
    "    wind[40:41] = [25]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']\n",
    "df_data['wind'] = wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          start_times=[3, 11, 33, 38],\n",
    "                                          fixes=True,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and constraints variations\n",
    "* Parameters to be variated:\n",
    "    * delay times\n",
    "    * shift times\n",
    "    * costs\n",
    "    * efficiency\n",
    "    * longer term energy limits: recovery time and maximum activations\n",
    "    * short-term energy limits: recovery time and short term limit\n",
    "* Constraints to be analyzed:\n",
    "    * optional constraints for Gils (2015) &rarr; included in long- and short-term energy limits analysis\n",
    "    * overall energy limits (activate / deactive) &rarr; see in long-term energy limits analysis\n",
    "    * additional constraint (eq. 10 from Zerrahn & Schill 2015)\n",
    " \n",
    "The cases for the parameter and constraints variations are chosen in such a way that the effects of parameter and constraints variations become visible. Therefore, the model setting and constraints formulation has been carefully analyzed in order to find out, how the model setting and individual parameters and constraints should behave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations in delay time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define settings for delay time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Variation von Verschiebedauern'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [125]\n",
    "demand[5:6] = [75]\n",
    "\n",
    "demand[11:12] = [150]\n",
    "demand[13:14] = [50]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [25]\n",
    "    demand[29:30] = [175]\n",
    "\n",
    "    demand[36:37] = [0]\n",
    "    demand[40:41] = [200]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='Nachfragevariation mit unterschiedlicher Amplitude')\n",
    "plot_case_residual(data=df_data, case='dem_variation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare variations in delay time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "delay_times = [1, 2, 3, 4, 5]\n",
    "approach_dict = {}\n",
    "\n",
    "for dt in delay_times:\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    print(\"delay time {:d}\".format(dt))\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:\n",
    "\n",
    "        approach_dict[(approach, dt)] = \\\n",
    "            start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                        param_variations='_delay_time_{:d}'.format(dt),\n",
    "                        method='delay', delay_time=dt, efficiency=1, approach=approach,\n",
    "                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                        addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(12,8), \n",
    "                        shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                        start_times=[4, 11, 26, 36],\n",
    "                        fixes=True,\n",
    "                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True,\n",
    "                  param_name=\"delay_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations in shift time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define settings for shift time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_duration'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[6:8] = [125] * 2\n",
    "demand[8:10] = [75] * 2\n",
    "\n",
    "demand[15:18] = [150] * 3\n",
    "demand[18:21] = [50] * 3\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[34:38] = [0] * 4\n",
    "    demand[38:42] = [200] * 4\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation_duration')\n",
    "plot_case_residual(data=df_data, case='dem_variation_duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare variations in shift time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "shift_times = [1, 2, 3, 4, 5]\n",
    "approach_dict = {}\n",
    "\n",
    "for st in shift_times:\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    print(\"shift time {:d}\".format(st))\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:\n",
    "\n",
    "        approach_dict[(approach, st)] = \\\n",
    "            start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                        param_variations='_shift_time_{:d}'.format(st),\n",
    "                        method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                        cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                        addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                        shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                        start_times=[6, 15, 34],\n",
    "                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes,\n",
    "                        shift_time=st)\n",
    "        \n",
    "        if approach in [\"DLR\", \"IER\"]:\n",
    "            approach_dict[(approach, st)] = \\\n",
    "                start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                            param_variations='_fixes_shift_time_{:d}'.format(st),\n",
    "                            method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                            cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                            cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                            addition=False, fixes=True,\n",
    "                            recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                            shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                            start_times=[6, 15, 34],\n",
    "                            introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                            use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes,\n",
    "                            shift_time=st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True,\n",
    "                  param_name=\"shift_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations in DSM costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define settings for cost analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [125]\n",
    "demand[5:6] = [75]\n",
    "\n",
    "demand[11:12] = [150]\n",
    "demand[13:14] = [50]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [25]\n",
    "    demand[29:30] = [175]\n",
    "\n",
    "    demand[36:37] = [0]\n",
    "    demand[40:41] = [200]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation')\n",
    "plot_case_residual(data=df_data, case='dem_variation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare variations in costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "cost_dsm = [0.1, 1, 16.74*2, 16.75*2, 32.5*2, 200]\n",
    "approach_dict = {}\n",
    "\n",
    "for cost in cost_dsm:\n",
    "    \n",
    "    # Cost is split half on upwards and downwards shift; shedding gets high costs\n",
    "    cost_dsm_up = cost/2\n",
    "    cost_dsm_down_shift = cost/2\n",
    "    cost_dsm_down_shed = 1000 * cost\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    print(\"costs {:.4f}\".format(cost))\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:\n",
    "\n",
    "        approach_dict[(approach, cost)] = \\\n",
    "            start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                        param_variations='_dsm_cost_{:f}'.format(cost_dsm_up),\n",
    "                        method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                        addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                        start_times=[4, 11, 26, 36],\n",
    "                        shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True,\n",
    "                  param_name=\"costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reset costs values:** Reset DSM costs to original values for further considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_dsm = 0.1\n",
    "\n",
    "# Cost is split half on upwards and downwards shift; shedding gets high costs\n",
    "cost_dsm_up = cost_dsm/2\n",
    "cost_dsm_down_shift = cost_dsm/2\n",
    "cost_dsm_down_shed = 1000 * cost_dsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations in DSM efficiency\n",
    "So far, only examples with an efficiency of one, i.e. no losses have been considered.<br>\n",
    "If efficiencies are introduces, load shifts can be balanced out except for these losses.\n",
    "\n",
    "> _Note:_\n",
    "> * _For the DLR approach two different variants are considered: the basic one \"core\" and another one including own fixes. &rarr; Here, the added condition forbidding unbalanced load shifts prevents unexpected behaviour._\n",
    "> * _The TUD approach does not consider efficiencies and is therefore excluded._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define settings for efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_eff'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [125]\n",
    "demand[5:6] = [75]\n",
    "\n",
    "demand[11:12] = [150]\n",
    "demand[13:14] = [50]\n",
    "    \n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [25]\n",
    "    demand[29:30] = [175]\n",
    "\n",
    "    demand[36:37] = [0]\n",
    "    demand[40:41] = [200]\n",
    "\n",
    "    demand[43:44] = [0]\n",
    "    demand[45:46] = [200]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation')\n",
    "plot_case_residual(data=df_data, case='dem_variation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare variations in efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "efficiencies = [1, 0.95, 0.8, 0.2]\n",
    "approach_dict = {}\n",
    "\n",
    "for eff in efficiencies:\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    print(\"efficiency {:.2f}\".format(eff))\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    eff_assigned = eff\n",
    "    for approach in approaches:\n",
    "        \n",
    "        # exclude TUD approach (no efficiencies)\n",
    "        if not approach == \"TUD\":\n",
    "            approach_dict[(approach, eff)] = \\\n",
    "                start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                            param_variations='_efficiency_{:f}'.format(eff),\n",
    "                            method='delay', delay_time=4, efficiency=eff_assigned, approach=approach,\n",
    "                            cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                            cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                            start_times=[4, 11, 26, 36, 43],\n",
    "                            addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                            shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                            introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                            use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)\n",
    "        \n",
    "        # variant with own fixes\n",
    "        if approach == \"DLR\":            \n",
    "            approach_dict[(approach+\"_fixes\", eff)] = \\\n",
    "                start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                            param_variations='_fixes_efficiency_{:f}'.format(eff),\n",
    "                            method='delay', delay_time=4, efficiency=eff_assigned, approach=approach,\n",
    "                            cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                            cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                            addition=False, fixes=True,\n",
    "                            recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                            shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                            introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                            use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True,\n",
    "                  param_name=\"efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations in recovery time / max. activations\n",
    "\n",
    "The approaches differ in the way, a recovery time resp. a limit for a given time frame is set. The following elements are used for depicting this.\n",
    "\n",
    "| approach | parameter used | description |\n",
    "| ---- | ---- | ---- |\n",
    "| DIW | recovery time | defines the time between the end of a shifting process and the begin of a subsequent one |\n",
    "| DLR | $n_{YearLimit}$ | defines the maximum amount of shifts within the optimization timeframe (one year) |\n",
    "| IER | cumulative shift time | defines the overall time within the optimization timeframe (one year) where shifts in upwards resp. downwards direction may occur |\n",
    "| TUD | annual frequency shift | defines the maximum amount of shifts within the optimization timeframe (one year) |\n",
    "\n",
    "The following anologies can be identified which are used to harmonize parameterization:\n",
    "\n",
    "$$(1) \\qquad f_a = n_{YearLimit} = \\frac{T} {t_{delay} + t_{recovery}}$$\n",
    "$$(2) \\qquad t_{cum\\_shift} = n_{YearLimit} \\cdot t_{shift}$$\n",
    "\n",
    "where\n",
    "\n",
    "$ f_a $ : annual frequency shift<br>\n",
    "$ T $ : overall optimization timeframe (in realistic examples usually one year)<br>\n",
    "$ t_{cum\\_shift} $ : cumulative shifting time (pos / neg)\n",
    "\n",
    "> _Note:_<br>\n",
    "> _For the DLR approach two different variants are considered: the basic one \"core\" and another one including own fixes. &rarr; Here, the added conditions preventing shifts which cannot be balanced within the optimization timeframe prevent unexpected behaviour._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic variant\n",
    "Use the same generation and demand patterns as for most of the other parameter variations above (except for one extra shift at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "recovery_time = [None, 2, 4, 16, 44]\n",
    "approach_dict = {}\n",
    "\n",
    "for rt in recovery_time:\n",
    "    \n",
    "    if rt is not None:\n",
    "        param_variations='_recovery_time_{:d}'.format(rt)\n",
    "    else:\n",
    "        param_variations='_no_recovery_time'\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    if not rt is None:\n",
    "        print(\"recovery time {:d}; max. activations: {:.0f}; cumulative shift time {:.0f}\".format(rt, \n",
    "            len(df_data)//(4+rt), len(df_data)//(4+rt) * 2))\n",
    "    else:\n",
    "        print(\"no limit on recovery time\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:            \n",
    "        \n",
    "        approach_dict[(approach, rt)] = \\\n",
    "            start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                        param_variations=param_variations,\n",
    "                        method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                        addition=False, recovery_time_shift=rt, recovery_time_shed=4, figsize=(15,8), \n",
    "                        shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                        start_times=[4, 11, 26, 36, 43],\n",
    "                        ActivateYearLimit=True,\n",
    "                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional variant\n",
    "Show dependency of recovery time on consumption pattern for DIW and DLR approach:\n",
    "* _DIW approach_: Since recovery time constraint is introduced only for upshifts and cap_up, it restricts load shifting further if initial load increases are needed to balance (demand) variations.\n",
    "* _DLR approach_: Effectively an energy limit is posed for the initial shifts. If all initial shifts are downshifts, the energy limit should become binding.\n",
    "* This can be identified by adapting case 2b from above in the following way:\n",
    "    1. The order of the demand variation for the third and fourth use case of load shifting in case 2b is switched, i.e. an initial load decrease is now needed.\n",
    "    2. Change the amplitudes: Slightly increase it for the first shift cycle and change the amplitudes for second and fourth shifting cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_switched'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [150]\n",
    "demand[5:6] = [50]\n",
    "\n",
    "demand[11:12] = [200]\n",
    "demand[13:14] = [0]\n",
    "\n",
    "#demand[17:18] = [200]\n",
    "#demand[20:21] = [0]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [150]\n",
    "    demand[29:30] = [50]\n",
    "\n",
    "    #demand[31:32] = [150]\n",
    "    #demand[35:36] = [50]    \n",
    "    \n",
    "    demand[36:37] = [175]\n",
    "    demand[40:41] = [25]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation_switched')\n",
    "plot_case_residual(data=df_data, case='dem_variation_switched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "recovery_time = [None, 2, 4, 16, 44]\n",
    "approach_dict = {}\n",
    "\n",
    "for rt in recovery_time:\n",
    "    \n",
    "    if rt is not None:\n",
    "        param_variations='_recovery_time_{:d}'.format(rt)\n",
    "        param_variations_fixes='_fixes_recovery_time_{:d}'.format(rt)\n",
    "    else:\n",
    "        param_variations='_no_recovery_time'\n",
    "        param_variations_fixes='_fixes_no_recovery_time'\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    if not rt is None:\n",
    "        print(\"recovery time {:d}; max. activations: {:.0f}; cumulative shift time {:.0f}\".format(rt, \n",
    "            len(df_data)//(4+rt), len(df_data)//(4+rt) * 2))\n",
    "    else:\n",
    "        print(\"no limit on recovery time\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:            \n",
    "        \n",
    "        approach_dict[(approach, rt)] = \\\n",
    "            start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                        param_variations=param_variations,\n",
    "                        method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                        cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                        start_times=[4, 11, 17, 26, 31, 36],\n",
    "                        addition=False, recovery_time_shift=rt, recovery_time_shed=4, figsize=(15,8), \n",
    "                        shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                        ActivateYearLimit=True,\n",
    "                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)\n",
    "        \n",
    "        # variant with own fixes\n",
    "        if approach == \"DLR\":            \n",
    "            approach_dict[(approach+\"_fixes\", rt)] = \\\n",
    "                start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                            param_variations=param_variations_fixes,\n",
    "                            method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                            cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                            cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                            addition=False, fixes=True,\n",
    "                            recovery_time_shift=rt, recovery_time_shed=4, figsize=(15,8), \n",
    "                            shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                            ActivateYearLimit=True,\n",
    "                            introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                            use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare DIW and DLR approach separately (recovery_time and t_dayLimit)\n",
    "Dependent on how parameterization of the parameters recovery_time from DIW and t_dayLimit from DLR is set, they can be used to model more or less the same thing, i.e. and energy limit imposed over a certain (smaller) timeframe. Hence, an additional comparison is made in the following where only the two approaches are compared to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "recovery_time = [2, 4, 16, 44]\n",
    "approach_dict = {}\n",
    "\n",
    "for rt in recovery_time:\n",
    "    \n",
    "    if rt is not None:\n",
    "        param_variations='_recovery_time_{:d}'.format(rt)\n",
    "    else:\n",
    "        param_variations='_no_recovery_time'\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    if not rt is None:\n",
    "        print(\"recovery time resp. t_dayLimit {:d}\".format(rt))\n",
    "    else:\n",
    "        print(\"no limit on recovery time resp. t_dayLimit\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:\n",
    "        \n",
    "        if approach in [\"DIW\", \"DLR\"]:\n",
    "        \n",
    "            approach_dict[(approach, rt)] = \\\n",
    "                start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                            param_variations=param_variations,\n",
    "                            method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                            cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                            cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                            addition=False, fixes=True,\n",
    "                            recovery_time_shift=rt, recovery_time_shed=4, figsize=(15,8), \n",
    "                            shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                            ActivateYearLimit=False, ActivateDayLimit=True,\n",
    "                            t_dayLimit = rt, \n",
    "                            introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                            use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True,\n",
    "                  param_name=\"recovery_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations in amount of daily activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define settings for daily constraint analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_daily'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[4:5] = [175]\n",
    "demand[5:6] = [25]\n",
    "\n",
    "demand[11:12] = [200]\n",
    "demand[13:14] = [0]\n",
    "\n",
    "demand[17:18] = [200]\n",
    "demand[19:20] = [0]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[26:27] = [25]\n",
    "    demand[29:30] = [175]\n",
    "\n",
    "    demand[36:37] = [0]\n",
    "    demand[40:41] = [200]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare variations in amount of daily activations\n",
    "\n",
    "For two approaches, there is a limit on the amount of energy shifted per day.\n",
    "For the TUD approach from Ladwig (2018) this is a mandatory thing, for the DLR approach from Gils (2015) it is optional.\n",
    "\n",
    "The following elements are used for depicting this.\n",
    "\n",
    "| approach | parameter used | description |\n",
    "| ---- | ---- | ---- |\n",
    "| DLR | $t_{DayLimit}$ | defines the maximum time for up- resp. downshifts, i.e. the maximum amount of subsequent hours for up- resp. downshifts (not including the current hour) |\n",
    "| TUD | daily frequency shift | defines the maximum amount of shifts per day |\n",
    "\n",
    "The following anology can be identified which is used to harmonize parameterization:\n",
    "\n",
    "$$ \\qquad t_{DayLimit} =  \\frac{24}{f_d}-1$$\n",
    "\n",
    "where\n",
    "\n",
    "$ f_d $ : daily frequency shift<br>\n",
    "\n",
    "Since the other approaches from DLR and IER do not use a day limit, they are not considered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "day_limit = [24, 6, 2, 1]\n",
    "approach_dict = {}\n",
    "\n",
    "for dl in day_limit:\n",
    "    \n",
    "    param_variations='_day_limit_{:d}'.format(dl)\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    print(\"day limit {:d}; t_DayLimit: {:d}\".format(dl, int(24/dl-1)))\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:\n",
    "        if approach in [\"DLR\", \"TUD\"]:\n",
    "        \n",
    "            approach_dict[(approach, dl)] = \\\n",
    "                start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                            param_variations=param_variations,\n",
    "                            method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                            cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                            cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                            addition=False, fixes=True,\n",
    "                            recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                            shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                            ActivateDayLimit=True, daily_frequency_shift=dl,\n",
    "                            introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                            use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation of optional constraint corresponding to Eq. 10 from Zerrahn and Schill (2015a)\n",
    "* Set parameter addition to True. Contraint limiting overall amount of DSM capacity (sum in both directions) is introduced.\n",
    "* delay_time is set to three. Otherwise there would be no simulatneous activation in both directions for the example load and generation pattern (case 2b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define settings for analysis of optional overall capacity limit constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_add'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "demand[5:6] = [125]\n",
    "demand[6:7] = [75]\n",
    "\n",
    "demand[13:14] = [150]\n",
    "demand[15:16] = [50]\n",
    "\n",
    "if timesteps > 24:\n",
    "    demand[25:26] = [25]\n",
    "    demand[28:29] = [175]\n",
    "\n",
    "    demand[36:37] = [0]\n",
    "    demand[40:41] = [200]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze overall capacity limit constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "additions = [False, True]\n",
    "approach_dict = {}\n",
    "\n",
    "for add in additions:\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    print(\"constrain overall DSM capacity {0}\".format(addition))\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:\n",
    "\n",
    "        approach_dict[(approach, add)] = \\\n",
    "            start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                        param_variations='_addition_{0}'.format(addition),\n",
    "                        method='delay', delay_time=3, efficiency=1, approach=approach,\n",
    "                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                        addition=add, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8),\n",
    "                        start_times=[5, 13, 25, 36],\n",
    "                        fixes=True,\n",
    "                        shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True,\n",
    "                  param_name=\"add_constr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks\n",
    "Do some benchmarks for objective value as well as execution times.\n",
    "The following setting is used:\n",
    "* A for loop is used in order to create different random data samples.\n",
    "* A random demand pattern for 168 hours is synthesized.\n",
    "* A (random) band is created to account for upwards and downwards capacity limits.\n",
    "* Objective values as well as runtimes are evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress pyomo warnings for the iterations\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the objective benchmark\n",
    "Do the actual objective benchmark and store the results into a dict:\n",
    "* Iterate over a given range (number of iterations)\n",
    "* Initialize random sample data for demand\n",
    "* Run the model for each approach and store the results to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [int(el/2 * 168) for el in range(1, 5, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running the benchmark, set boolean variable to True\n",
    "#target_benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a benchmark for the objective value of the approaches\n",
    "objective_dict = {}\n",
    "\n",
    "if target_benchmark:\n",
    "    \n",
    "    # generation data is the same for each iteration so it is put outside the loop\n",
    "    datetimeindex = pd.date_range(start=\"2013-01-01 00:00\", periods=periods[2], freq=\"H\")\n",
    "    df_bm_data = pd.DataFrame(index=datetimeindex)\n",
    "    df_bm_data[\"wind\"] = 100\n",
    "    df_bm_data[\"pv\"] = 0\n",
    "\n",
    "    for iteration in range(100):\n",
    "        \n",
    "        # Create random demand data\n",
    "        np.random.seed(iteration)\n",
    "        \n",
    "        df_bm_data[\"demand_el\"] = 100 + np.random.randint(low=-10, \n",
    "                                                          high=10, \n",
    "                                                          size=df_bm_data.shape[0]) * 5\n",
    "        df_bm_data[\"Cap_up\"] = 50 + np.random.randint(low=-5, \n",
    "                                                      high=5, \n",
    "                                                      size=df_bm_data.shape[0]) * 5\n",
    "        df_bm_data[\"Cap_do\"] = 50 + np.random.randint(low=-5, \n",
    "                                                      high=5, \n",
    "                                                      size=df_bm_data.shape[0]) * 5\n",
    "        \n",
    "        for approach in approaches:\n",
    "            #if approach == \"IER\":\n",
    "            res = start_model(df_bm_data, timesteps=len(df_bm_data), plot=False, save=False, case=case, \n",
    "                              method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                              cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                              cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                              addition=False, fixes=True, recovery_time_shift=None, \n",
    "                              recovery_time_shed=4, \n",
    "                              start_times=list(range(0, len(df_bm_data), 4)),\n",
    "                              figsize=(15,8), \n",
    "                              shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                              introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                              use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)[2]['objective']\n",
    "            objective_dict[\"{}_{}\".format(approach, iteration)] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process objective benchmark results\n",
    "Evaluate the objective benchmark results:\n",
    "* Create a dict indexed by approaches only\n",
    "* Calculate mean values for the objective values from all iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dict = {}\n",
    "obj_mean_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    obj_dict[approach] = {k: v for k, v in objective_dict.items() if approach in k}\n",
    "    obj_mean_dict[approach] = np.mean(list(obj_dict[approach].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_mean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the runtime benchmark\n",
    "Do the actual runtime benchmark and store the results into a dict:\n",
    "* Initialize random sample data for demand (same data is used in order to focus on runtime, not influenced by any parameter or solver effects)\n",
    "* Iterate over a given range (number of iterations) but use the same data in each iteration\n",
    "* Run the model for each approach and store the solver time results to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running the benchmark, set boolean variable to True\n",
    "#performance_benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a benchmark for the objective value of the approaches\n",
    "runtime_dict = {}\n",
    "\n",
    "if performance_benchmark:\n",
    "    \n",
    "    # Data used is the same for each iteration, so it can be set outside the loop\n",
    "    datetimeindex = pd.date_range(start=\"2013-01-01 00:00\", periods=periods[2], freq=\"H\")\n",
    "    df_bm_data = pd.DataFrame(index=datetimeindex)\n",
    "    df_bm_data[\"wind\"] = 100\n",
    "    df_bm_data[\"pv\"] = 0\n",
    "    \n",
    "    np.random.seed(42)\n",
    "\n",
    "    df_bm_data[\"demand_el\"] = 100 + np.random.randint(low=-10, \n",
    "                                                      high=10, \n",
    "                                                      size=df_bm_data.shape[0]) * 5\n",
    "    df_bm_data[\"Cap_up\"] = 50 + np.random.randint(low=-5, \n",
    "                                                  high=5, \n",
    "                                                  size=df_bm_data.shape[0]) * 5\n",
    "    df_bm_data[\"Cap_do\"] = 50 + np.random.randint(low=-5, \n",
    "                                                  high=5, \n",
    "                                                  size=df_bm_data.shape[0]) * 5\n",
    "    \n",
    "    # Compare overall execution time\n",
    "    for approach in approaches:\n",
    "        #if approach == \"IER\":\n",
    "        %timeit -r 10 -n 10 start_model(df_bm_data, timesteps=len(df_bm_data), plot=False, save=False, case=case, method='delay', delay_time=4, efficiency=1, approach=approach, cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed, addition=False, fixes=True, recovery_time_shift=None, recovery_time_shed=4, start_times=list(range(0, len(df_bm_data), 4)), figsize=(15,8), shed_eligibility=True, shed_time=4, n_yearLimit_shed=6, introduce_second_dsm_unit=introduce_second_dsm_unit, use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)\n",
    "    \n",
    "    # Compare solver time only (iteration)\n",
    "    for iteration in range(100):\n",
    "\n",
    "        for approach in approaches:\n",
    "            #if approach == \"IER\":\n",
    "            res = start_model(df_bm_data, timesteps=len(df_bm_data), plot=False, save=False, case=case, \n",
    "                              method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                              cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                              cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                              addition=False, fixes=True, recovery_time_shift=None, recovery_time_shed=4,\n",
    "                              start_times=list(range(0, len(df_bm_data), 4)),\n",
    "                              figsize=(15,8), \n",
    "                              shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                              introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                              use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)[2]['solver']['Time']\n",
    "            runtime_dict[\"{}_{}\".format(approach, iteration)] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process performance benchmark results\n",
    "Evaluate the performance benchmark results:\n",
    "* Create a dict indexed by approaches only\n",
    "* Calculate mean values for the runtime values from all iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dict = {}\n",
    "run_mean_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    run_dict[approach] = {k: v for k, v in runtime_dict.items() if approach in k}\n",
    "    run_mean_dict[approach] = np.nanmean(list(run_dict[approach].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More stylized examples\n",
    "In the following, two other example settings are constructed:\n",
    "* One very stylized toy model with a given no cost generation and no other generation unit forcing DSM usage\n",
    "* Another model with a stylized PV infeed and two backup generation units, a coal and a gas power plant. For this example dsm is defined to have costs in between the units, so it should be utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very stylized DSM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'stylized'\n",
    "\n",
    "# Base data set\n",
    "df_data = df_base.copy()\n",
    "wind = [100] * timesteps\n",
    "\n",
    "# wind pattern\n",
    "wind_down = range(200, 25, -25)\n",
    "wind_up = range(50, 225, 25)\n",
    "\n",
    "# Manipulate wind\n",
    "wind[0:len(wind_down)] = list(wind_down)\n",
    "wind[len(wind_down):len(wind_down)+len(wind_up)] = list(wind_up)\n",
    "\n",
    "if timesteps > 24:\n",
    "    wind[24:24+len(wind_up)] = list(wind_up)\n",
    "    wind[24+len(wind_up):24+len(wind_up)+len(wind_down)] = list(wind_down)\n",
    "    \n",
    "\n",
    "df_data['wind'] = wind\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case=case)\n",
    "plot_case_residual(data=df_data, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                                          cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, fixes=True,\n",
    "                                          recovery_time_shift=None, recovery_time_shed=4,\n",
    "                                          start_times=list(range(0, len(df_data), 4)),\n",
    "                                          figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes,\n",
    "                                          include_coal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PV example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Note: This example is similar to the one by Guido Plessmann and Julian Endres given in the oemof.solph documentation, see:_\n",
    "> * https://oemof.readthedocs.io/en/stable/oemof_solph.html#sinkdsm-custom (accessed 19.08.2020) and\n",
    "> * https://oemof.files.wordpress.com/2019/12/20191206_dsm_modeling_in_oemof_solph_10th_oemof_dev_meeting_plessmann.pdf (accessed 19.08.2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case=\"pv_example\"\n",
    "\n",
    "# Create some data\n",
    "pv_day = [(-(1 / 6 * x ** 2) + 6) / 6 for x in range(-6, 7)]\n",
    "pv_ts = [0] * 6 + pv_day + [0] * 6\n",
    "data_dict = {\"demand_el\": [3] * len(pv_ts),\n",
    "             \"wind\": [0] * len(pv_ts),\n",
    "             \"pv\": pv_ts,\n",
    "             \"Cap_up\": [0.5] * len(pv_ts),\n",
    "             \"Cap_do\": [0.5] * len(pv_ts)}\n",
    "df_data = pd.DataFrame.from_dict(data_dict)\n",
    "df_data.set_index(df_base.index[:len(df_data)], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost and capacity parameters (efficiency has to be taken into account)\n",
    "cost_coal = 13 / 0.4\n",
    "cost_gas = 25 / 0.4\n",
    "cost_dsm = (cost_coal+cost_gas)/2\n",
    "nom_cap_coal = 2.5 / 0.4\n",
    "nom_cap_gas = 1 / 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since DSM activation is quite sensitive to costs associated with DSM, this is further analyzed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0, len(df_data), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "cost_dsm = [1, (cost_coal+1)/2, (cost_coal+cost_gas)/2, 1000]\n",
    "approach_dict = {}\n",
    "\n",
    "for cost in cost_dsm:\n",
    "    \n",
    "    # Cost is split half on upwards and downwards shift; shedding gets high costs\n",
    "    cost_dsm_up = cost/2\n",
    "    cost_dsm_down_shift = cost/2\n",
    "    cost_dsm_down_shed = 1000 * cost\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    print(\"costs {:.4f}\".format(cost))\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")\n",
    "    for approach in approaches:\n",
    "        \n",
    "        approach_dict[(approach, cost)] = \\\n",
    "            start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case,\n",
    "                        param_variations='_dsm_cost_{:f}'.format(cost_dsm_up),\n",
    "                        method='delay', delay_time=6, efficiency=1, approach=approach,\n",
    "                        cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                        cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                        addition=False, fixes=True,\n",
    "                        recovery_time_shift=None, recovery_time_shed=4, \n",
    "                        start_times=list(range(0, len(df_data), 6)),\n",
    "                        figsize=(15,8), \n",
    "                        shed_eligibility=False, shed_time=4, n_yearLimit_shed=6,\n",
    "                        introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                        use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes,\n",
    "                        include_coal=True, include_gas=True, \n",
    "                        nom_cap_coal=nom_cap_coal, nom_cap_gas=nom_cap_gas, nom_cap_pv=3.5,\n",
    "                        ax1_ylim = [0, 4], ax2_ylim = [-3, 1], include_generators=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results_table(approach_dict, save_results, MultiIndex=True, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_dict[(\"IER\", 1.0)][0].iloc[6:13].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reset costs values:** Reset DSM costs to original values for further considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_dsm = 0.1\n",
    "\n",
    "# Cost is split half on upwards and downwards shift; shedding gets high costs\n",
    "cost_dsm_up = cost_dsm/2\n",
    "cost_dsm_down_shift = cost_dsm/2\n",
    "cost_dsm_down_shed = 1000 * cost_dsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# More realistic data setting\n",
    "Input data from the aggregation_example.ipynb written by Julian Endres is used, see: https://github.com/windnode/SinkDSM_example/blob/master/aggregation_example.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial parameter settings\n",
    "* Determine model settings (timesteps)\n",
    "* Only consider project methods (other example covering different aggregation levels is not considered here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'realistic'\n",
    "\n",
    "project = 'methods'\n",
    "start_model = '2013-03-01 00:00:00+0100'\n",
    "\n",
    "# Set time range for model (further possible values are uncommented)\n",
    "#timesteps_model = 'all'\n",
    "timesteps_model = 24 * 7\n",
    "#timesteps_model = '2013-03-03 00:00:00'\n",
    "\n",
    "# Print model start and end information\n",
    "print('Model begins at:')\n",
    "print(start_model)\n",
    "\n",
    "if timesteps_model == 'all':\n",
    "    print('covers {} timesteps'.format(timesteps_model))\n",
    "elif isinstance(timesteps_model, int):\n",
    "    print('ends after {} timesteps'.format(timesteps_model))\n",
    "elif isinstance(timesteps_model, str):\n",
    "    print('ends at: {}'.format(timesteps_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input directory and file\n",
    "input_directory = 'data/{}/'.format(project)\n",
    "input_file = 'scaled_data_2.csv'\n",
    "folder = input_directory + input_file\n",
    "filename_data = os.path.join(os.path.dirname('__file__'), folder)\n",
    "\n",
    "# Read in data and do timezone adjustments\n",
    "data = pd.read_csv(filename_data,\n",
    "                   sep=\";\",\n",
    "                   decimal=',',\n",
    "                   encoding='utf-8',\n",
    "                   parse_dates=True,\n",
    "                   date_parser=pd.to_datetime)\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "tz = 'Europe/Berlin'\n",
    "data.set_index('timestamp', inplace=True)\n",
    "data.index = pd.to_datetime(data.index, utc=True).tz_convert(tz)\n",
    "data.rename(columns={'cap_up':'Cap_up', 'cap_do': 'Cap_do'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model results for realistic toy model\n",
    "Run method defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_model, datetimeindex, dict_meta_model = \\\n",
    "    create_realistic_example(data, start_model, timesteps_model, approaches,\n",
    "                             plot=False, save=save_figs, method='delay', \n",
    "                             delay_time=4, efficiency=1, \n",
    "                             start_times=list(range(0, len(data), 4)),\n",
    "                             fixes=True,\n",
    "                             cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, \n",
    "                             cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                             addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                             shed_eligibility=True, shed_time=4, n_yearLimit_shed=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define presets and do data preparation for output plots\n",
    "* Define some settings in order to create another kind of visualization for demand response results.\n",
    "* Transfer the data in such a shape that it can easily be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presets\n",
    "figure_size = (15,6)\n",
    "\n",
    "# start of plot\n",
    "start = datetimeindex[0]\n",
    "\n",
    "# plotted time range\n",
    "timesteps = 24 * 3 + 3 #*31\n",
    "steps = pd.date_range(start, periods=timesteps, freq='H', tz='Europe/Berlin') # stepsize\n",
    "\n",
    "plot_style = 'normal'\n",
    "\n",
    "color=['teal','goldenrod','grey','coral','olive','orchid', 'silver', 'seagreen', 'slateblue']\n",
    "drawstyle= {'scientific':{'step':'pre','drawstyle':'steps-post'},'normal':{'step':None,'drawstyle':None }}\n",
    "ds = drawstyle[plot_style]\n",
    "\n",
    "tz = 'Europe/Berlin'\n",
    "end = steps[-1]\n",
    "\n",
    "# Show some logging info\n",
    "print('start: {}'.format(start))\n",
    "print('end:   {}'.format(end))\n",
    "print('Approaches evaluated:')\n",
    "print([keys for keys in dict_df_model.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show and plot the results\n",
    "* Show total values per approach\n",
    "* Show plots in order to visually inspect differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show total values for the timeframe considered\n",
    "dsm = pd.DataFrame()\n",
    "\n",
    "for index, df in dict_df_model.items():\n",
    "    dsm[index]  =df.abs().sum().round()\n",
    "    dsm.loc['gen_total', index] = df[['wind', 'pv', 'coal1']].sum().sum().round()\n",
    "    dsm.loc['gen_EE', index] = df[['wind', 'pv']].sum().sum().round()\n",
    "\n",
    "display(dsm.loc[['demand_el','dsm_tot','excess',\n",
    "                 'cap_up', 'cap_do',\n",
    "                 'gen_total','gen_EE',\n",
    "                 'wind', 'pv', 'coal1']].T.style.bar(axis=0 ,color='goldenrod'))\n",
    "\n",
    "if save_results:\n",
    "    name = 'results_' + case + '.csv'\n",
    "    dsm.loc[['demand_el','dsm_tot','excess',\n",
    "                 'cap_up', 'cap_do',\n",
    "                 'gen_total','gen_EE',\n",
    "                 'wind', 'pv', 'coal1']].T.to_csv('./graphics/' + name, sep=';', decimal=',')\n",
    "    print(name + ' saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_TODO: Fix plots xaxis_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['wind', 'pv', 'coal1']\n",
    "plots = len([s for s in dict_df_model.keys()])\n",
    "fig_all, ax = plt.subplots(max(plots,2),1,figsize=(15,plots*4))\n",
    "\n",
    "i=0\n",
    "keys=[]\n",
    "for _, (key, df) in enumerate(dict_df_model.items()):\n",
    "    \n",
    "    keys.append(key)\n",
    "    ax[i].set_title(key)\n",
    "\n",
    "    # plot demand\n",
    "    ax[i] = df.loc[steps,'demand_el'].plot(ax=ax[i], drawstyle=ds['drawstyle'], style='--', color='black')\n",
    "    ax[i] = df.loc[steps,'demand_dsm'].plot(ax=ax[i], drawstyle=ds['drawstyle'], style='--', color='crimson')\n",
    "\n",
    "    # calc & plot upper capacity\n",
    "    cap_up = df.loc[steps,'demand_el'] + df.loc[steps,'cap_up']\n",
    "    cap_up.name='cap_up'\n",
    "    ax[i] = cap_up.plot(ax=ax[i], drawstyle=ds['drawstyle'], style='-.', color='green')\n",
    "\n",
    "    # calc & plot lower capacity\n",
    "    cap_down = df.loc[steps,'demand_el'] - df.loc[steps,'cap_do']\n",
    "    cap_down.name='cap_do'\n",
    "    ax[i] = cap_down.plot(ax=ax[i], drawstyle=ds['drawstyle'], style='-.', color='white')\n",
    "        \n",
    "    # plot dsm acumulated\n",
    "    ax[i] = df.loc[steps, 'dsm_acum'].plot(ax=ax[i], drawstyle='steps-post', style='-.', color='indigo')\n",
    "    \n",
    "    # area plot for generation units\n",
    "    upper = 0\n",
    "    lower = 0\n",
    "    for gen, col in enumerate(df[column]):\n",
    "        upper += df.copy().loc[steps, col]\n",
    "        upper.name = col\n",
    "        ax[i].fill_between(steps, lower, upper, step=ds['step'], facecolor=color[gen], label=col)\n",
    "        lower = upper.copy()\n",
    "\n",
    "    ax[i].set_ylabel('kW')\n",
    "    ax[i].set_xticks(pd.date_range(start=start, periods=timesteps/3, freq='3h', tz=tz))\n",
    "    ax[i].xaxis.set_major_formatter((mdates.DateFormatter('%H h')))\n",
    "    \n",
    "    #ax[i].xaxis.set_minor_locator(mdates.DayLocator(tz = df.index.tz))\n",
    "    #ax[i].xaxis.set_minor_formatter(mdates.DateFormatter('%d.%m', tz=df.index.tz))\n",
    "    #ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%H h', tz=df.index.tz)) \n",
    "    #ax[i].xaxis.grid(True, which=\"minor\")\n",
    "    #ax[i].xaxis.grid(False, which=\"major\")\n",
    "    #ax[i].set_facecolor='white'\n",
    "    \n",
    "    plt.sca(ax[i])\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "handles, labels = ax[i-1].get_legend_handles_labels()\n",
    "ax[i-1].legend(labels,\n",
    "             bbox_to_anchor=(0., -.5, 1., .102),\n",
    "             loc=3, ncol=4,\n",
    "             mode=\"expand\",\n",
    "             borderaxespad=0.1,\n",
    "             facecolor='silver')\n",
    "fig_all.subplots_adjust(hspace = 0.4)\n",
    "plt.show()\n",
    "\n",
    "if save_figs:\n",
    "    name = 'realistic_example_plot.png'\n",
    "    fig_all.savefig('./graphics/' + name, bbox_inches='tight')\n",
    "    print(name + ' saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare energy on hold, capacity limits as well as activations up / down\n",
    "* Energy on hold: The amount of energy that has to be compensated by load shifts in the other direction again. &rarr; A positive value means that upwards shifts are necessary for balancing.\n",
    "* Capacity limits: The capacity available for upwards resp. downwards shifts. &rarr; Identical since this is set as an input parameter.\n",
    "* Activations in upwards / downwards direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_results_plot(dict_df_model, start, timesteps, tz, 'dsm_acum', False,\n",
    "                  figure_size, 'DR - energy on hold', 'kWh', ds['drawstyle'], color, save=save_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_results_plot(dict_df_model, start, timesteps, tz, ['cap_up', 'cap_do'], {'cap_up':False, 'cap_do': True},\n",
    "                  figure_size, 'DR - capacity limits up / down', 'kW', ds['drawstyle'], color, save=save_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_results_plot(dict_df_model, start, timesteps, tz, ['dsm_up', 'dsm_do_shift'], {'dsm_up':False, 'dsm_do_shift': True},\n",
    "                  figure_size, 'DR - activations up / down', 'kW', 'steps-post', color, save=save_figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gils, Hans Christian (2015): Balancing of Intermittent Renewable Power Generation by Demand Response and Thermal Energy Storage, Stuttgart, http://dx.doi.org/10.18419/opus-6888, accessed 16.08.2019, pp. 67-70.\n",
    "* Ladwig, Theresa (2018): Demand Side Management in Deutschland zur Systemintegration erneuerbarer Energien, Dresden, https://nbn-resolving.org/urn:nbn:de:bsz:14-qucosa-236074, accessed 02.05.2020, pp. 90-93.\n",
    "* Steurer, Martin (2017): Analyse von Demand Side Integration im Hinblick auf eine effiziente und umweltfreundliche Energieversorgung, Stuttgart, [10.18419/opus-9181](http://dx.doi.org/10.18419/opus-9181), accessed 17.08.2019, pp. 80-82.\n",
    "* Zerrahn, Alexander and Schill, Wolf-Peter (2015a): On the representation of demand-side management in power system models, in: Energy (84), pp. 840-845, [10.1016/j.energy.2015.03.037](http://dx.doi.org/10.1016/j.energy.2015.03.037), accessed 16.08.2019, pp. 842-843.\n",
    "* Zerrahn, Alexander and Schill, Wolf-Peter (2015b): A Greenfield Model to Evaluate Long-Run Power Storage Requirements for High Shares of Renewables, DIW Discussion Papers, No. 1457."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
