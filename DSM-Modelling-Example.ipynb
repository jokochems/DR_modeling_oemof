{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling demand response: comparison of modelling approaches\n",
    "\n",
    "## Purpose and background\n",
    "\n",
    "* This notebook is based on an implementation of Julian Endres created within the wind note project, see: https://github.com/windnode/SinkDSM_example/blob/master/DSM-Modelling.ipynb\n",
    "* It's main purpose is to compare different implementations for demand response modelling.\n",
    "* The modelling approaches considered are the following ones:\n",
    "    * Zerrahn & Schill (2015)\n",
    "    * Steurer (2017)\n",
    "    * Gils (2015)\n",
    "    * Ladwig (2018)\n",
    "\n",
    "## Method\n",
    "\n",
    "To compare the modelling approaches, the following methodology is applied:\n",
    "* A toy model is set up\n",
    "* Different situations are depicted using the toy model:\n",
    "    * Constant demand & generation throughout\n",
    "    * Constant demand & varying generation\n",
    "    * Varying demand & constant generation\n",
    "    * Both varying demand & varying generation\n",
    "* In addition to that, a more realistic example model is considered as well.\n",
    "* For all approaches, a separate model instance is created containing the respective demand response component. Hereby the same parametrization is used - as far as possible\n",
    "* A benchmark is carried out, whereby the following elements are evaluated:\n",
    "    * (Overall) amount of DSM activations\n",
    "        * Capacity shifted\n",
    "        * Energy shifted\n",
    "    * DSM patterns\n",
    "    * Overall system costs\n",
    "    * Runtime / solver time\n",
    "* Some of the benchmarks are only evaluated for certain model configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Imports\n",
    "* Standard imports\n",
    "* Import the different implementations for demand response components\n",
    "* Import module `plotting.py` for extracting results and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import oemof.solph as solph\n",
    "from oemof.network.network import Node\n",
    "\n",
    "# Import the different alternative implementations\n",
    "import oemof_SinkDSM as DSM_DIW\n",
    "import oemof_DR_component_DLR_naming_adjusted as DSM_DLR\n",
    "import oemof_DR_component_DLR_naming_adjusted_shifting_classes as DSM_DLR_ShiftClass\n",
    "import oemof_DR_component_DLR_naming_adjusted_no_shed as DSM_DLR_NoShed\n",
    "import oemof_DR_component_IER_naming_adjusted as DSM_IER\n",
    "import oemof_DR_component_TUD_naming_adjusted as DSM_TUD\n",
    "\n",
    "# Import module for plotting (results handling)\n",
    "import plotting as plt_dsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine matplotlib settings\n",
    "register_matplotlib_converters()\n",
    "\n",
    "SMALL_SIZE = 11\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## base dataset\n",
    "plt_dsm.make_directory('graphics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter settings\n",
    "* General parameter settings for controlling the notebooks workflow\n",
    "* Special parameter settings for DSM parameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameter settings\n",
    "Control **workflow** of notebook:\n",
    "* *version*: One of 'simple' or 'advanced' &rarr; Determines the structure and duration of demand and generation peaks / drops\n",
    "* *save_figs*: If True, all figures will be saved in the graphics folder.\n",
    "* *save_results*: If True, overall amounts of demand response activations will be saved to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to control overall workflow\n",
    "version = 'simple'\n",
    "#version = 'advanced'\n",
    "save_figs = True\n",
    "save_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSM parameter settings\n",
    "Define major **parameters concerning demand response modelling**\n",
    "* *aproaches*: List of the approaches used for demand response modelling\n",
    "* *addition*: Boolean parameter indicating, whether or not to include an additional \"logic\" constraint into the other DSM modelling approaches that is similar to equation 10 of Zerrahn & Schill (2015)\n",
    "* *efficiency*: Consider a pontential efficiency loss for those modelling approaches which depict DSM efficiency (all except for Ladwig 2018).\n",
    "* *recovery_time*: Consider a pontential recovery time for those modelling approaches which depict it (only Zerrahn & Schill 2015).\n",
    "* *ActivateYearLimit*: Boolean variable indicating whether or not to use a limit for DSM activations per year (only applicable for Gils 2015).\n",
    "* *ActivateDayLimit*: Boolean variable indicating whether or not to use a limit for DSM activations per day resp. per rolling window (only applicable for Gils 2015).\n",
    "\n",
    "Determine **costs for demand response**:\n",
    "* *include_costs*: If True, (small) variable costs will be included.\n",
    "* *cost_dsm*: Overall variable costs for demand response which have to be splitted up to up and downwards shifts\n",
    "* *cost_dsm_up*: Costs for upwards shifts (_defaults to have of the overall costs_)\n",
    "* *cost_dsm_down*: Costs for downwards shifts (_defaults to have of the overall costs_)\n",
    "\n",
    "Introduce special control variables for controlling the **workflow**, especially for approach from DLR (Gils 2015):\n",
    "* *introduce_second_dsm_unit*: If True, a second demand response unit with the same parameterization will be introduced.\n",
    "* *few_timesteps*: If True, for the simple example the timeset will be limited to 9 timesteps in order to increase readability of the .lp-files\n",
    "* *use_shifting_classes*: If True, shifting classes will be applied in the approach from DLR (Gils 2015)\n",
    "* *use_no_shed*: If True, the approach from DLR (Gils 2015) withouth a load shedding implementation will be utilized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters focussing on demand response modelling\n",
    "approaches = [\"DIW\", \"DLR\", \"IER\", \"TUD\"]\n",
    "addition = False\n",
    "efficiency = 1\n",
    "recovery_time = None\n",
    "ActivateYearLimit = False\n",
    "ActivateDayLimit = False\n",
    "\n",
    "# Determine cost consideration\n",
    "include_costs = True\n",
    "\n",
    "if include_costs:\n",
    "    cost_dsm = 0.1\n",
    "\n",
    "else:\n",
    "    cost_dsm = 0\n",
    "\n",
    "# Cost is split half on upwards and downwards shift; shedding gets high costs\n",
    "cost_dsm_up = cost_dsm/2\n",
    "cost_dsm_down_shift = cost_dsm/2\n",
    "cost_dsm_down_shed = 1000 * cost_dsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables for demand response modelling\n",
    "introduce_second_dsm_unit = False\n",
    "few_timesteps = True\n",
    "\n",
    "# Define whether or not to use the shifting classes approach for DLR (Gils 2015) -> not working yet!\n",
    "use_no_shed = False\n",
    "use_shifting_classes = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools for setting up a toy energy system model\n",
    "For the testing, a **toy energy system** is set up including:\n",
    "- Coal PP\n",
    "- Wind PP\n",
    "- PV PP\n",
    "- DSM Sink\n",
    "- shortage\n",
    "- excess\n",
    "\n",
    "**Rules for DSM parametrization**:\n",
    "\n",
    "The following rules apply for parameters which are not part of every modelling approach:<br>\n",
    "__*NOTE: These rules may / should be altered later to see the effect of the individual parameter!*__\n",
    "* shift (resp. interference) times: These will be defined half of the delay time and symmetrical in the first place.\n",
    "* optional parameters & constraints: These will be ignored in the first place.\n",
    "* additional constraints: These will also be ignored in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and solve the model\n",
    "A function is defined here for setting up and solving the toy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data, datetimeindex, directory, project, approach,\n",
    "                 delay_time, shed_time, cost_dsm_up, cost_dsm_down_shift, \n",
    "                 cost_dsm_down_shed, efficiency,\n",
    "                 shed_eligibility, shift_eligibility, introduce_second_dsm_unit,\n",
    "                 **kwargs):\n",
    "    \"\"\" Function to create and solve the model. \"\"\"\n",
    "    \n",
    "    # Special kwargs (one approach only)\n",
    "    method = kwargs.get('method', 'delay')\n",
    "    shift_interval = kwargs.get('shift_interval', 24)\n",
    "    recovery_time_shift = kwargs.get('recovery_time_shift', None)\n",
    "    recovery_time_shed = kwargs.get('recovery_time_shed', 24)\n",
    "    use_no_shed = kwargs.get('use_no_shed', False)\n",
    "    use_shiting_classes = kwargs.get('use_shifting_classes', False)\n",
    "    \n",
    "    addition = kwargs.get('addition', 24)\n",
    "    \n",
    "    ActivateYearLimit = kwargs.get('ActivateYearLimit', False)\n",
    "    ActivateDayLimit = kwargs.get('ActivateDayLimit', False)\n",
    "    n_yearLimit_shift = kwargs.get('n_yearLimit_shift', 0)\n",
    "    n_yearLimit_shed = kwargs.get('n_yearLimit_shed', 0)\n",
    "    t_dayLimit = kwargs.get('t_dayLimit', 0)\n",
    "    \n",
    "\n",
    "    # ----------------- Energy System ----------------------------\n",
    "    \n",
    "    # Create Energy System\n",
    "    es = solph.EnergySystem(timeindex=datetimeindex)\n",
    "                           #groupings=[type])\n",
    "    Node.registry = es\n",
    "\n",
    "    # Create Busses\n",
    "    b_coal_1 = solph.Bus(label='bus_coal_1')\n",
    "    b_elec = solph.Bus(label='bus_elec')\n",
    "\n",
    "    # Create Sources\n",
    "    s_coal_p1 = solph.Source(label='source_coal_p1',\n",
    "                             outputs={\n",
    "                                b_coal_1: solph.Flow(\n",
    "                                    nominal_value=10000,\n",
    "                                    variable_costs=13)}\n",
    "                             )\n",
    "\n",
    "    s_wind = solph.Source(label='wind',\n",
    "                          outputs={\n",
    "                              b_elec: solph.Flow(\n",
    "                                  fix=data['wind'][datetimeindex],\n",
    "                                  nominal_value=1)}\n",
    "                          )\n",
    "\n",
    "    s_pv = solph.Source(label='pv',\n",
    "                        outputs={\n",
    "                            b_elec: solph.Flow(\n",
    "                                fix=data['pv'][datetimeindex],\n",
    "                                nominal_value=1)}\n",
    "                        )\n",
    "\n",
    "    # Create Transformer\n",
    "    cfp_1 = solph.Transformer(label='pp_coal_1',\n",
    "                              inputs={b_coal_1: solph.Flow()},\n",
    "                              outputs={\n",
    "                                  b_elec: solph.Flow(\n",
    "                                      variable_costs=0)},\n",
    "                              conversion_factors={b_elec: 0.4}\n",
    "                              )\n",
    "    \n",
    "    # Create DSM units\n",
    "\n",
    "    # Define kwargs that are identical for all DSM units\n",
    "    kwargs_all = {'label': 'demand_dsm',\n",
    "                  'inputs': {b_elec: solph.Flow(variable_costs=0)},\n",
    "                  'demand': data['demand_el'][datetimeindex],\n",
    "                  'capacity_up': data['Cap_up'][datetimeindex],\n",
    "                  'capacity_down': data['Cap_do'][datetimeindex],\n",
    "                  'delay_time': delay_time,\n",
    "                  'shed_time': shed_time,\n",
    "                  'cost_dsm_up': cost_dsm_up,\n",
    "                  'cost_dsm_down_shift': cost_dsm_down_shift,\n",
    "                  'cost_dsm_down_shed': cost_dsm_down_shed,\n",
    "                  'efficiency': efficiency,\n",
    "                  'shed_eligibility': shed_eligibility,\n",
    "                  'shift_eligibility': shift_eligibility}\n",
    "    \n",
    "    # Define kwargs that differ dependent on approach chosen\n",
    "    kwargs_dict = {\n",
    "        'DIW': {'method': 'delay',\n",
    "                'shift_interval': shift_interval,\n",
    "                'recovery_time_shift': recovery_time_shift,\n",
    "                'recovery_time_shed': recovery_time_shed},\n",
    "                   \n",
    "        'IER': {'shift_time_up': delay_time,\n",
    "                'shift_time_down': delay_time,\n",
    "                'cumulative_shift_time': len(data.loc[datetimeindex,:]),\n",
    "                'cumulative_shed_time': len(data.loc[datetimeindex,:]),\n",
    "                'addition': addition},\n",
    "        \n",
    "        'DLR': {'shift_time': delay_time/2,\n",
    "                'ActivateYearLimit': ActivateYearLimit,\n",
    "                'ActivateDayLimit': ActivateDayLimit,\n",
    "                'n_yearLimit_shift': n_yearLimit_shift,\n",
    "                'n_yearLimit_shed': n_yearLimit_shed,\n",
    "                't_dayLimit': t_dayLimit,\n",
    "                'addition': addition},\n",
    "        \n",
    "        'TUD': {'shift_time_down': delay_time/2,\n",
    "                'postpone_time': delay_time/2,\n",
    "                'annual_frequency_shift': len(data.loc[datetimeindex,:])/delay_time,\n",
    "                'annual_frequency_shed': len(data.loc[datetimeindex,:])/shed_time,\n",
    "                'daily_frequency_shift': 24/delay_time,\n",
    "                'addition': addition}\n",
    "                  }\n",
    "    \n",
    "    # Create a second (identical) dsm unit for testing purposes\n",
    "    # TODO: Fix this -> does not work (yet)!\n",
    "    # Throws a key error\n",
    "    # There seems to be a problem with the grouping not working properly!\n",
    "    # But oddly it works for oemof.solph.custom.Link which has a pretty similar implementation ...\n",
    "    \n",
    "    # Optionally attribute half of the potential to a second identical dsm unit with a new label\n",
    "    if introduce_second_dsm_unit:\n",
    "        kwargs_all['demand'] = kwargs_all['demand']/2\n",
    "        kwargs_all['capacity_up'] = kwargs_all['capacity_up']/2\n",
    "        kwargs_all['capacity_down'] = kwargs_all['capacity_down']/2\n",
    "        \n",
    "        kwargs_all_manipulated = kwargs_all.copy()\n",
    "        kwargs_all_manipulated['label'] = 'demand_dsm2'\n",
    "    \n",
    "    # Actually build the units\n",
    "    if approach == \"DIW\":\n",
    "            \n",
    "        demand_dsm = DSM_DIW.SinkDSM(**kwargs_all,\n",
    "                                     **kwargs_dict[approach])\n",
    "        \n",
    "        if introduce_second_dsm_unit:\n",
    "            demand_dsm2 = DSM_DIW.SinkDSM(**kwargs_all_manipulated,\n",
    "                                          **kwargs_dict[approach])\n",
    "\n",
    "    elif approach == \"IER\":\n",
    "        demand_dsm = DSM_IER.SinkDSI(**kwargs_all,\n",
    "                                     **kwargs_dict[approach])\n",
    "        \n",
    "        if introduce_second_dsm_unit:\n",
    "            demand_dsm2 = DSM_IER.SinkDSI(**kwargs_all_manipulated,\n",
    "                                          **kwargs_dict[approach])\n",
    "    \n",
    "    elif approach == \"DLR\":\n",
    "        \n",
    "        # Use approach without shifing classes but with shedding\n",
    "        if not (use_no_shed or use_shifting_classes):\n",
    "            demand_dsm = DSM_DLR.SinkDR(**kwargs_all,\n",
    "                                        **kwargs_dict[approach])\n",
    "        \n",
    "        # Use approach without shedding (and without shifting classes)\n",
    "        elif use_no_shed:\n",
    "            demand_dsm = DSM_DLR_NoShed.SinkDR(**kwargs_all,\n",
    "                                               **kwargs_dict[approach])\n",
    "            \n",
    "\n",
    "            if introduce_second_dsm_unit:\n",
    "                demand_dsm2 = DSM_DLR_NoShed.SinkkDR(**kwargs_all_manipulated,\n",
    "                                                     **kwargs_dict[approach])\n",
    "        \n",
    "        # Use approach with shifing classes\n",
    "        else:\n",
    "            demand_dsm = DSM_DLR_ShiftClass.SinkDR(**kwargs_all,\n",
    "                                                    **kwargs_dict[approach])\n",
    "\n",
    "    elif approach == \"TUD\":\n",
    "        demand_dsm = DSM_TUD.SinkDSM(**kwargs_all,\n",
    "                                     **kwargs_dict[approach])\n",
    "\n",
    "        if introduce_second_dsm_unit:\n",
    "            demand_dsm2 = DSM_TUD.SinkDSM(**kwargs_all_manipulated,\n",
    "                                          **kwargs_dict[approach])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"No valid value for approach. Must be one of ['DIW', 'IER', 'DLR', 'TUD']\")\n",
    "\n",
    "    # Backup excess / shortage\n",
    "    excess = solph.Sink(label='excess_el',\n",
    "                        inputs={b_elec: solph.Flow(variable_costs=1)}\n",
    "                        )\n",
    "\n",
    "    s_shortage_el = solph.Source(label='shortage_el',\n",
    "                                 outputs={\n",
    "                                     b_elec: solph.Flow(\n",
    "                                         variable_costs=200)}\n",
    "                                 )\n",
    "\n",
    "    # -------------------------- Create Model ----------------------\n",
    "    \n",
    "    #pprint.pprint(es.groups, width=1)\n",
    "    \n",
    "    # Create Model\n",
    "    model = solph.Model(es)\n",
    "\n",
    "    # Solve Model\n",
    "    model.solve(solver='gurobi', solve_kwargs={'tee': False})\n",
    "\n",
    "    # Write LP File\n",
    "    filename = os.path.join(os.path.dirname('__file__'), directory, project +'.lp')\n",
    "    model.write(filename, io_options={'symbolic_solver_labels': True})\n",
    "\n",
    "    # Save Results\n",
    "    es.results['main'] = solph.processing.results(model)\n",
    "    es.results['meta'] = solph.processing.meta_results(model)\n",
    "    es.dump(dpath=None, filename=None)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model results and plot the model\n",
    "A function is defined here to extract results from the model and plot the model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_model(df_data, timesteps, **kwargs):\n",
    "    \"\"\" Function to extract model results and plot the model. \"\"\"\n",
    "    \n",
    "    approach = kwargs.get('approach', 'DIW')\n",
    "    \n",
    "    # Control plotting and processing\n",
    "    case = kwargs.get('case', 'constant') \n",
    "    plot = kwargs.get('plot', False)\n",
    "    figure_size = kwargs.get('figsize', (15,10))\n",
    "    show = kwargs.get('show', False)\n",
    "    save = kwargs.get('save', False)\n",
    "    \n",
    "    # ----------------- Input Data & Timesteps ----------------------------\n",
    "\n",
    "    # Provide directory\n",
    "    project = 'demand_shift_' + approach + '_' + case\n",
    "    directory = './'\n",
    "\n",
    "    # Data manipulation\n",
    "    data = df_data\n",
    "\n",
    "    # Timestamp\n",
    "    datetimeindex = pd.date_range(start='1/1/2013',\n",
    "                                  periods=timesteps,\n",
    "                                  freq='H')\n",
    "    \n",
    "    # ----------------- DSM Parameterization ----------------------------\n",
    "    \n",
    "    introduce_second_dsm_unit = kwargs.get('introduce_second_dsm_unit', False)\n",
    "    \n",
    "    # kwargs for all approaches\n",
    "    delay_time = kwargs.get('delay_time', 1)\n",
    "    shed_time = kwargs.get('shed_time', 1)\n",
    "    cost_dsm_up = kwargs.get('cost_dsm_up', 0)\n",
    "    cost_dsm_down_shift = kwargs.get('cost_dsm_down_shift', 0)\n",
    "    cost_dsm_down_shed = kwargs.get('cost_dsm_down_shed', 0)\n",
    "    efficiency = kwargs.get('efficiency', 1)\n",
    "    shed_eligibility = kwargs.get('shed_eligibility', False)\n",
    "    shift_eligibility = kwargs.get('shift_eligibility', True)\n",
    "    \n",
    "    # kwargs that differ dependent on approach chosen\n",
    "    kwargs_dict = {\n",
    "        'DIW': {'method': kwargs.get('method', None),\n",
    "                'shift_interval': kwargs.get('shift_interval', None),\n",
    "                'recovery_time_shift': kwargs.get('recovery_time_shift', None),\n",
    "                'recovery_time_shed': kwargs.get('recovery_time_shed', 24)},\n",
    "                   \n",
    "        'IER': {'shift_time_up': delay_time/2,\n",
    "                'shift_time_down': delay_time/2,\n",
    "                'cumulative_shift_time': len(data.loc[datetimeindex,:]),\n",
    "                'cumulative_shed_time': len(data.loc[datetimeindex,:]),\n",
    "                'addition': kwargs.get('addition', False)},\n",
    "        \n",
    "        'DLR': {'shift_time': delay_time/2,\n",
    "                'ActivateYearLimit': kwargs.get('ActivateYearLimit', False),\n",
    "                'ActivateDayLimit': kwargs.get('ActivateDayLimit', False),\n",
    "                'n_yearLimit_shift': kwargs.get('n_yearLimit_shift', 0),\n",
    "                'n_yearLimit_shed': kwargs.get('n_yearLimit_shed', 0),\n",
    "                't_dayLimit': kwargs.get('t_dayLimit', 0),\n",
    "                'addition': kwargs.get('addition', False)},\n",
    "        \n",
    "        'TUD': {'shift_time_down': delay_time/2,\n",
    "                'postpone_time': delay_time/2,\n",
    "                'annual_frequency_shift': len(data.loc[datetimeindex,:])/delay_time,\n",
    "                'annual_frequency_shed': len(data.loc[datetimeindex,:])/shed_time,\n",
    "                'daily_frequency_shift': 24/delay_time,\n",
    "                'addition': kwargs.get('addition', False)}              \n",
    "                  }   \n",
    "\n",
    "    # Introduce another dict for controlling the approaches workflows\n",
    "    # So far, these only apply for DLR approach (might be removed later on)\n",
    "    control_dict = {\n",
    "        'DIW':{},\n",
    "        'IER':{},\n",
    "        'DLR':{'use_no_shed': kwargs.get('use_no_shed', True),\n",
    "               'use_shifting_classes': kwargs.get('use_shifting_classes', False)},\n",
    "        'TUD':{}      \n",
    "    }\n",
    "    \n",
    "    # ----------------- Create & Solve Model ----------------------------\n",
    "\n",
    "    # Create model   \n",
    "    model = create_model(data,\n",
    "                         datetimeindex, \n",
    "                         directory, \n",
    "                         project,\n",
    "                         approach,\n",
    "                         delay_time, \n",
    "                         shed_time, \n",
    "                         cost_dsm_up, \n",
    "                         cost_dsm_down_shift,\n",
    "                         cost_dsm_down_shed,\n",
    "                         efficiency,\n",
    "                         shed_eligibility,\n",
    "                         shift_eligibility,\n",
    "                         introduce_second_dsm_unit,\n",
    "                         **kwargs_dict[approach],\n",
    "                         **control_dict[approach])\n",
    "    \n",
    "    #model.pprint()\n",
    "\n",
    "    # Get Results\n",
    "    es = solph.EnergySystem()\n",
    "    es.restore(dpath=None, filename=None)\n",
    "    \n",
    "    results = es.results['main']\n",
    "    meta = es.results['meta']\n",
    "    \n",
    "    # Export data\n",
    "    df_gesamt = plt_dsm.extract_results(model, approach, **control_dict[approach])\n",
    "    #display(df_gesamt)\n",
    "    \n",
    "    # write data to csv\n",
    "    #df_gesamt.to_csv(directory + project + '_data_dump.csv')\n",
    "    \n",
    "    # ----------------- Plot Results ----------------------------\n",
    "    if plot:\n",
    "        plt_dsm.plot_dsm(df_gesamt,\n",
    "                directory,\n",
    "                project,\n",
    "                **control_dict[approach],\n",
    "                days=2,\n",
    "                show=show,\n",
    "                figsize=figure_size,\n",
    "                approach=approach,\n",
    "                save=save)\n",
    "    \n",
    "    return df_gesamt, model, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot case (availability and generation data)\n",
    "Function to visualize the case considered for the simple example model\n",
    "* Show availability, i.e. capacity bounds for DSM\n",
    "* Show demand before DSM and generation pattern as well as \"residual load\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case(data, case='constant', **kwargs):\n",
    "    \"\"\" Function to plot the case considered.\n",
    "    \n",
    "    Case is defined by availability time series, i.e. capacity bounds for DSM and\n",
    "    demand before DSM as well as generation pattern.\n",
    "    \"\"\"\n",
    "    show = kwargs.get('show', True)\n",
    "    save_figs = kwargs.get('save_figs', True)\n",
    "    \n",
    "    # Plot demand, wind generation and DR capacity limits\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    _ = plt.title('Generation and demand for case \"' + case + '\"')\n",
    "\n",
    "    # Define xaxis ticks\n",
    "    ax.xaxis_date()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m - %H h'))  # ('%d.%m-%H h'))\n",
    "    ax.set_xlim(df_data.index.values[0] - pd.Timedelta(1, 'h'), \n",
    "                df_data.index.values[0] + pd.Timedelta(1, 'h'))\n",
    "    plt.xticks(pd.date_range(start=df_data.index.values[0], \n",
    "                             periods=len(df_data)+1, \n",
    "                             freq='H'), rotation=90)\n",
    "\n",
    "    ax.plot(df_data.index, df_data['demand_el'].values, drawstyle=\"steps-post\", label=\"demand\")\n",
    "    ax.plot(df_data.index, df_data['wind'].values, drawstyle=\"steps-post\", label=\"generation\")\n",
    "\n",
    "    # Cap_up and Cap_do only included for proper alignment here\n",
    "    ax.plot(df_data.index, (df_data['demand_el'] + df_data['Cap_up']).values, \n",
    "            drawstyle=\"steps-post\", color=\"limegreen\", label=\"upper limit\")\n",
    "    ax.plot(df_data.index, (df_data['demand_el'] - df_data['Cap_do']).values, \n",
    "            drawstyle=\"steps-post\", color=\"lightcoral\", label=\"lower limit\")\n",
    "    \n",
    "    _ = ax.set_yticks(range(-(data.Cap_do.max()-100), data.Cap_up.max()+125, 25))\n",
    "    ax.legend(bbox_to_anchor=(0., -0.5, 1., 0.102), loc=2, ncol=2, borderaxespad=0.)\n",
    "    _ = ax.set_xlabel(\"Time in h\")\n",
    "    _ = ax.set_ylabel(\"capacity in MW \\n(demand, generation,\\n abs. limits)\")\n",
    "\n",
    "    plt.grid(alpha=0.6)\n",
    "    \n",
    "    # Delta MW on secondary y_axis\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m - %H h'))  # ('%d.%m-%H h'))\n",
    "    ax2.set_xlim(df_data.index.values[0] - pd.Timedelta(1, 'h'), \n",
    "                df_data.index.values[-1] + pd.Timedelta(1, 'h'))\n",
    "    plt.xticks(pd.date_range(start=df_data.index.values[0], \n",
    "                             periods=len(df_data)+1, \n",
    "                             freq='H'), rotation=90)\n",
    "\n",
    "    ax2.plot(df_data.index, df_data.Cap_up.values, drawstyle=\"steps-post\", #secondary_y=True, \n",
    "             linestyle=\":\", color=\"darkgreen\", label=\"Cap_up (right axis)\")\n",
    "    ax2.plot(df_data.index, (df_data.Cap_do*-1).values, drawstyle=\"steps-post\", #secondary_y=True, \n",
    "             linestyle=\":\", color=\"saddlebrown\", label=\"Cap_do (right axis)\")\n",
    "    \n",
    "    _ = ax2.set_yticks(range(-data.Cap_do.max(), data.Cap_up.max()+50, 50))\n",
    "    ax2.legend(bbox_to_anchor=(0., -0.5, 1., 0.102), loc=1, ncol=1, borderaxespad=0.)\n",
    "    _ = ax2.set_ylabel(\"difference $\\Delta$ MW \\n(Cap_up, Cap_do)\")#\n",
    "    \n",
    "    # Do axis aligment\n",
    "    plt_dsm.align_yaxis(ax, -(data.Cap_do.max()-100), ax2, -data.Cap_do.max())\n",
    "    plt_dsm.align_yaxis(ax, data.Cap_up.max()+100, ax2, data.Cap_up.max())\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save_figs:\n",
    "        name = 'toy-model_' + case + '.png'\n",
    "        fig.savefig('./graphics/' + name)\n",
    "        plt.close()\n",
    "        print(name + \" saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case_residual(data, case='constant', **kwargs):\n",
    "    \"\"\" Function to plot the residual load for the respective case. \n",
    "    \n",
    "    Residual load is defined here as the difference between\n",
    "    generic generation and demand, i.e., what is actually to be balanced.\n",
    "    \"\"\"\n",
    "    show = kwargs.get('show', True)\n",
    "    save_figs = kwargs.get('save_figs', True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    _ = plt.title('\"Residual load\" for case \"' + case + '\"')\n",
    "\n",
    "    ax.xaxis_date()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m - %H h'))  # ('%d.%m-%H h'))\n",
    "    ax.set_xlim(df_data.index.values[0] - pd.Timedelta(1, 'h'), \n",
    "                df_data.index.values[0] + pd.Timedelta(1, 'h'))\n",
    "    plt.xticks(pd.date_range(start=df_data.index.values[0], \n",
    "                             periods=len(df_data)+1, \n",
    "                             freq='H'), rotation=90)\n",
    "\n",
    "    ax.plot(df_data.index, (df_data['wind'] - df_data['demand_el']).values, drawstyle=\"steps-post\", \n",
    "            linestyle=\"-.\", label=\"residual load\", color=\"black\")\n",
    "    _ = ax.set_yticks(range(-100,125,25))\n",
    "    plt.grid()\n",
    "    _ = ax.set_ylabel(\"MW \\n(residual load)\")\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save_figs:\n",
    "        name = 'toy-model_' + case + '_residual.png'\n",
    "        fig.savefig('./graphics/' + name)\n",
    "        plt.close()\n",
    "        print(name + \" saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model results for realistic toy model\n",
    "A separate function similar to the one above is defined, which is tailored at a more realistic toy model.\n",
    "* A loop over all approaches is directly integrated here.\n",
    "* Results are then added to a dict indexed by approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_realistic_example(data, start_model, timesteps_model, approaches, **kwargs):\n",
    "    \"\"\" Create and solve a more realistic example model. \"\"\"\n",
    "    \n",
    "    dict_df_model = {}\n",
    "    dict_meta_model = {}\n",
    "    \n",
    "    plot = kwargs.get('plot', False)\n",
    "    \n",
    "    directory=\"./\"\n",
    "\n",
    "    # Adjust Timesteps\n",
    "    start_model = pd.to_datetime(start_model, utc=True).tz_convert(tz)\n",
    "\n",
    "    if isinstance(timesteps_model, str):\n",
    "        if timesteps_model == 'all':\n",
    "            timesteps_model_in = data.index[-1]\n",
    "        else:\n",
    "            timesteps_model_in = timesteps_model\n",
    "\n",
    "        datetimeindex = pd.date_range(start=start_model,\n",
    "                                      end=timesteps_model_in, freq='H', tz=tz)\n",
    "\n",
    "    else:\n",
    "        timesteps_model_in = timesteps_model\n",
    "        datetimeindex = pd.date_range(start=start_model,\n",
    "                                      periods=timesteps_model_in, freq='H', tz=tz)\n",
    "    \n",
    "    # ----------------- DSM Parameterization ----------------------------\n",
    "    \n",
    "    introduce_second_dsm_unit = kwargs.get('introduce_second_dsm_unit', False)\n",
    "    \n",
    "    # kwargs for all approaches\n",
    "    delay_time = kwargs.get('delay_time', 1)\n",
    "    shed_time = kwargs.get('shed_time', 1)\n",
    "    cost_dsm_up = kwargs.get('cost_dsm_up', 0)\n",
    "    cost_dsm_down_shift = kwargs.get('cost_dsm_down_shift', 0)\n",
    "    cost_dsm_down_shed = kwargs.get('cost_dsm_down_shed', 0)\n",
    "    efficiency = kwargs.get('efficiency', 1)\n",
    "    shed_eligibility = kwargs.get('shed_eligibility', False)\n",
    "    shift_eligibility = kwargs.get('shift_eligibility', True)\n",
    "    \n",
    "    # kwargs that differ dependent on approach chosen\n",
    "    kwargs_dict = {\n",
    "        'DIW': {'method': kwargs.get('method', None),\n",
    "                'shift_interval': kwargs.get('shift_interval', None),\n",
    "                'recovery_time_shift': kwargs.get('recovery_time_shift', None),\n",
    "                'recovery_time_shed': kwargs.get('recovery_time_shed', 24)},\n",
    "                   \n",
    "        'IER': {'shift_time_up': delay_time/2,\n",
    "                'shift_time_down': delay_time/2,\n",
    "                'cumulative_shift_time': len(data.loc[datetimeindex,:]),\n",
    "                'cumulative_shed_time': len(data.loc[datetimeindex,:]),\n",
    "                'addition': kwargs.get('addition', False)},\n",
    "        \n",
    "        'DLR': {'shift_time': delay_time/2,\n",
    "                'ActivateYearLimit': kwargs.get('ActivateYearLimit', False),\n",
    "                'ActivateDayLimit': kwargs.get('ActivateDayLimit', False),\n",
    "                'n_yearLimit_shift': kwargs.get('n_yearLimit_shift', 0),\n",
    "                'n_yearLimit_shed': kwargs.get('n_yearLimit_shed', 0),\n",
    "                't_dayLimit': kwargs.get('t_dayLimit', 0),\n",
    "                'addition': kwargs.get('addition', False)},\n",
    "        \n",
    "        'TUD': {'shift_time_down': delay_time/2,\n",
    "                'postpone_time': delay_time/2,\n",
    "                'annual_frequency_shift': len(data.loc[datetimeindex,:])/delay_time,\n",
    "                'annual_frequency_shed': len(data.loc[datetimeindex,:])/shed_time,\n",
    "                'daily_frequency_shift': 24/delay_time,\n",
    "                'addition': kwargs.get('addition', False)}              \n",
    "                  }\n",
    "    \n",
    "    # Introduce another dict for controlling the approaches workflows\n",
    "    # So far, these only apply for DLR approach (might be removed later on)\n",
    "    control_dict = {\n",
    "        'DIW':{},\n",
    "        'IER':{},\n",
    "        'DLR':{'use_no_shed': kwargs.get('use_no_shed', False),\n",
    "               'use_shifting_classes': kwargs.get('use_shifting_classes', True)},\n",
    "        'TUD':{}      \n",
    "    }\n",
    "\n",
    "    # ----------------- Create & Solve Models ----------------------\n",
    "    \n",
    "    for approach in approaches:\n",
    "        \n",
    "        model = create_model(data,\n",
    "                             datetimeindex,\n",
    "                             directory,\n",
    "                             project,\n",
    "                             approach,\n",
    "                             delay_time, \n",
    "                             shed_time, \n",
    "                             cost_dsm_up, \n",
    "                             cost_dsm_down_shift, \n",
    "                             cost_dsm_down_shed, \n",
    "                             efficiency,\n",
    "                             shed_eligibility, \n",
    "                             shift_eligibility,\n",
    "                             introduce_second_dsm_unit,\n",
    "                             **kwargs_dict[approach],\n",
    "                             **control_dict[approach])\n",
    "        \n",
    "        # Get results\n",
    "        es = solph.EnergySystem()\n",
    "        es.restore(dpath=None, filename=None)\n",
    "        \n",
    "        results = es.results['main']\n",
    "        meta = es.results['meta']\n",
    "        \n",
    "        # Extract data from model\n",
    "        df_model = plt_dsm.extract_results(model, approach, **control_dict[approach])\n",
    "        df_model.index = pd.to_datetime(datetimeindex, utc=True).tz_convert(tz)\n",
    "\n",
    "        # Export data to dict\n",
    "        dict_df_model.update({'{}'.format(approach):df_model})\n",
    "        dict_meta_model.update({'{}'.format(approach):meta})\n",
    "\n",
    "    return dict_df_model, datetimeindex, dict_meta_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw results for more realistic toy model\n",
    "Plot certain columns of the results DataFrame only in order to be able to compare energy on hold, capacity limits etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_results_plot(dict_df_model, start, timesteps, tz, column, negate,\n",
    "                      figure_size, title, ylabel, drawstyle, color, **kwargs):\n",
    "    \"\"\" Functions draws results plots for realistic toy example \"\"\"\n",
    "    \n",
    "    save = kwargs.get('save', False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    ax.set_title(title, fontsize=15)\n",
    "    \n",
    "    keys=[]\n",
    "    for i, (key, df) in enumerate(dict_df_model.items()):\n",
    "        keys.append(key)\n",
    "        if isinstance(column, list):\n",
    "            for col in column:\n",
    "                if not negate[col]:\n",
    "                    df.loc[steps,col].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "                else:\n",
    "                    (df*(-1)).loc[steps,col].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "        else:\n",
    "            if not negate:\n",
    "                df.loc[steps,column].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "            else:\n",
    "                (df*(-1)).loc[steps,column].plot(ax=ax, drawstyle=drawstyle, color=color[i])\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(pd.date_range(start=start, periods=timesteps/3, freq='3H', tz=tz))\n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator(tz = df.index.tz))\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%d.%m', tz=df.index.tz))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('\\n%H h', tz=df.index.tz)) \n",
    "    ax.xaxis.grid(True, which=\"minor\")\n",
    "    ax.xaxis.grid(False, which=\"major\")\n",
    "    ax.hlines(y=0, xmin=start, xmax=end)\n",
    "\n",
    "    handles, _ = ax.get_legend_handles_labels() \n",
    "    if isinstance(column, list):\n",
    "        handles = handles[::len(column)]\n",
    "    labels = ['{}'.format(keys) for keys in keys]\n",
    "\n",
    "    ax.legend(handles, labels, bbox_to_anchor=(0., -.35, 1., .102), loc=3, ncol=2, mode=\"expand\", borderaxespad=0.1, fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    # Provide directory\n",
    "    project = 'demand_shift_' + case\n",
    "    if isinstance(column, list):\n",
    "        for col in column:\n",
    "            project = project + '_' + col\n",
    "    else:\n",
    "        project = project + '_' + column\n",
    "    directory = './'\n",
    "    \n",
    "    if save:\n",
    "        fig.set_tight_layout(True)\n",
    "        name = 'Plot_' + project + '_' + '.png'\n",
    "        fig.savefig(directory + 'graphics/' + name)\n",
    "        plt.close()\n",
    "        print(name + ' saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine base data set\n",
    "* A basic data set for the toy model is defined in the following.\n",
    "* To analyze different behaviour of the modelling approaches, this data set is modified in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 48\n",
    "\n",
    "# base data set\n",
    "demand = [100] * timesteps\n",
    "pv = [0] * timesteps\n",
    "capup = [100] * timesteps\n",
    "capdo = [100] * timesteps\n",
    "wind = [100] * timesteps\n",
    " \n",
    "base = [demand, wind, capup, capdo, pv]\n",
    "df_base = pd.DataFrame(list(zip(*base)))\n",
    "df_base.rename(columns={0:'demand_el',1:'wind', 2:'Cap_up', 3:'Cap_do', 4:'pv'}, inplace=True)\n",
    "df_base['timestamp'] = pd.date_range(start='1/1/2013', periods=timesteps, freq='H')\n",
    "df_base.set_index('timestamp', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "In the following, the results for the toy model considerations are depicted. This section is structured as follows:\n",
    "* At first, all approaches are analyzed for serving a flat demand with a constant generation.\n",
    "* In the next step, demand and generation are altered for some timesteps, first separate and then as well as combined.\n",
    "* In addition to the toy model considetations, a more realistic data setting is analyzed as well.\n",
    "* In the last step, the effect of different (optional) parameters and constraints is isolated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy model considerations\n",
    "Compare the approaches in a very stylized toy model setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: Only one demand variation and constant generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'simple'\n",
    "\n",
    "# Base data set\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "if version == 'simple':\n",
    "    demand[1:2] = [150]\n",
    "    demand[5:6] = [50]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='simple')\n",
    "plot_case_residual(data=df_data, case='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if few_timesteps:\n",
    "    df_data = df_data[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2a: Variations in demand (same amplitude) and constant generation\n",
    "Substitute flat demand by introducing one demand peak and one demand drop per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "if version == 'simple':\n",
    "    demand[4:5] = [150]\n",
    "    demand[5:6] = [50]\n",
    "    \n",
    "    demand[11:12] = [150]\n",
    "    demand[13:14] = [50]\n",
    "    \n",
    "    if timesteps > 24:\n",
    "        demand[26:27] = [50]\n",
    "        demand[29:30] = [150]\n",
    "        \n",
    "        demand[36:37] = [50]\n",
    "        demand[40:41] = [150]\n",
    "\n",
    "elif version == 'advanced':\n",
    "    demand[9:13] = [50] * 4\n",
    "    demand[18:22] = [150] * 4\n",
    "    if timesteps > 24:\n",
    "        demand[33:39] = [50] * 6\n",
    "        demand[42:48] = [150] * 6\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='constant')\n",
    "plot_case_residual(data=df_data, case='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2b: Variations in demand (changing amplitude) and constant generation\n",
    "Substitute flat demand by introducing one demand peak and one demand drop per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "if version == 'simple':\n",
    "    demand[4:5] = [125]\n",
    "    demand[5:6] = [75]\n",
    "    \n",
    "    demand[11:12] = [150]\n",
    "    demand[13:14] = [50]\n",
    "    \n",
    "    if timesteps > 24:\n",
    "        demand[26:27] = [25]\n",
    "        demand[29:30] = [175]\n",
    "        \n",
    "        demand[36:37] = [0]\n",
    "        demand[40:41] = [200]\n",
    "\n",
    "elif version == 'advanced':\n",
    "    demand[9:13] = [50] * 4\n",
    "    demand[18:22] = [150] * 4\n",
    "    if timesteps > 24:\n",
    "        demand[33:39] = [50] * 6\n",
    "        demand[42:48] = [150] * 6\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation')\n",
    "plot_case_residual(data=df_data, case='dem_variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2c: Variations in demand (changing starts) and constant generation\n",
    "Substitute flat demand by introducing one demand peak and one demand drop per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_amplitude'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "if version == 'simple':\n",
    "    demand[3:4] = [125]\n",
    "    demand[4:5] = [75]\n",
    "    \n",
    "    demand[15:16] = [150]\n",
    "    demand[17:18] = [50]\n",
    "    \n",
    "    if timesteps > 24:\n",
    "        demand[26:27] = [25]\n",
    "        demand[29:30] = [175]\n",
    "        \n",
    "        demand[37:38] = [0]\n",
    "        demand[41:42] = [200]\n",
    "\n",
    "elif version == 'advanced':\n",
    "    demand[9:13] = [50] * 4\n",
    "    demand[18:22] = [150] * 4\n",
    "    if timesteps > 24:\n",
    "        demand[33:39] = [50] * 6\n",
    "        demand[42:48] = [150] * 6\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation_amplitude')\n",
    "plot_case_residual(data=df_data, case='dem_variation_amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2d: Variations in demand (longer duration) and constant generation\n",
    "Substitute flat demand by introducing one demand peak and one demand drop per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_duration'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "if version == 'simple':\n",
    "    demand[6:8] = [125] * 2\n",
    "    demand[8:10] = [75] * 2\n",
    "    \n",
    "    demand[15:18] = [150] * 3\n",
    "    demand[18:21] = [50] * 3\n",
    "    \n",
    "    if timesteps > 24:\n",
    "        demand[34:38] = [25] * 4\n",
    "        demand[38:42] = [175] * 4\n",
    "\n",
    "elif version == 'advanced':\n",
    "    demand[9:13] = [50] * 4\n",
    "    demand[18:22] = [150] * 4\n",
    "    if timesteps > 24:\n",
    "        demand[33:39] = [50] * 6\n",
    "        demand[42:48] = [150] * 6\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation_duration')\n",
    "plot_case_residual(data=df_data, case='dem_variation_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2e: Variations in demand (longer shifts) and constant generation\n",
    "Substitute flat demand by introducing one demand peak and one demand drop per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_long_shifts'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "if version == 'simple':\n",
    "    demand[4:5] = [125]\n",
    "    demand[9:10] = [75]\n",
    "    \n",
    "    demand[19:20] = [150]\n",
    "    demand[25:26] = [50]\n",
    "    \n",
    "    if timesteps > 24:\n",
    "        demand[34:35] = [25]\n",
    "        demand[41:42] = [175]\n",
    "\n",
    "elif version == 'advanced':\n",
    "    demand[9:13] = [50] * 4\n",
    "    demand[18:22] = [150] * 4\n",
    "    if timesteps > 24:\n",
    "        demand[33:39] = [50] * 6\n",
    "        demand[42:48] = [150] * 6\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation_long_shifts')\n",
    "plot_case_residual(data=df_data, case='dem_variation_long_shifts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: Increase in demand and constant generation (use case for load shedding)\n",
    "Substitute flat demand by introducing one demand peak over several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'dem_variation_shed'\n",
    "\n",
    "# Data preperation: manipulate demand data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "\n",
    "# demand changes\n",
    "if version == 'simple':\n",
    "    demand[10:14] = [200] * 4\n",
    "\n",
    "elif version == 'advanced':\n",
    "    demand[10:14] = [200] * 4\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='dem_variation_shed')\n",
    "plot_case_residual(data=df_data, case='dem_variation_shed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _**NOTE:** A much lower value is used here for shedding costs in order to incentivize load shedding._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=0.1,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4: Variations in generation and constant demand\n",
    "Introduce wind peaks and wind drops of different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case = 'gen_variation'\n",
    "\n",
    "# Data preperation: manipulate wind data\n",
    "df_data = df_base.copy()\n",
    "wind = [100] * timesteps\n",
    "\n",
    "# wind changes\n",
    "if version == 'simple':\n",
    "    wind[3:4] = [0]\n",
    "    wind[10:11] = [175]\n",
    "    if timesteps > 24:\n",
    "        wind[39:40] = [200]\n",
    "        wind[46:47] = [25]\n",
    "\n",
    "if version == 'advanced':\n",
    "    wind[3:7] = [0] * 4\n",
    "    wind[21:22] = [175]\n",
    "    if timesteps > 24:\n",
    "        wind[38:42] = [200] * 4\n",
    "        wind[27:28] = [25]\n",
    "\n",
    "df_data['wind'] = wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='gen_variation')\n",
    "plot_case_residual(data=df_data, case='gen_variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5: Variations in demand and generation\n",
    "Demand and wind variations are introduced by forming a combination of cases 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'combined_variation'\n",
    "\n",
    "# Data preperation: manipulate demand and wind data\n",
    "df_data = df_base.copy()\n",
    "demand = [100] * timesteps\n",
    "wind = [100] * timesteps\n",
    "\n",
    "if version == 'simple':\n",
    "    # demand changes\n",
    "    demand[10:11] = [50]\n",
    "    demand[13:14] = [150]\n",
    "    if timesteps > 24:\n",
    "        demand[33:34] = [150]\n",
    "        demand[37:38] = [50]\n",
    "    \n",
    "    # wind changes\n",
    "    wind[3:4] = [0]\n",
    "    wind[10:11] = [175]\n",
    "    if timesteps > 24:\n",
    "        wind[38:39] = [200]\n",
    "        wind[45:46] = [25]\n",
    "\n",
    "elif version == 'advanced':\n",
    "    # demand changes\n",
    "    demand[9:13] = [50] * 4\n",
    "    demand[18:22] = [150] * 4\n",
    "    if timesteps > 24:\n",
    "        demand[33:39] = [50] * 6\n",
    "        demand[42:48] = [150] * 6\n",
    "        \n",
    "    # wind changes\n",
    "    wind[3:7] = [0] * 4\n",
    "    wind[21:22] = [175]\n",
    "    if timesteps > 24:\n",
    "        wind[38:42] = [200] * 4\n",
    "        wind[27:28] = [25]\n",
    "\n",
    "df_data['demand_el'] = demand\n",
    "df_data['Cap_up'] = [100] * timesteps + df_data['Cap_up'] - df_data['demand_el']\n",
    "df_data['Cap_do'] = [100] * timesteps + df_data['demand_el'] - df_data['Cap_do']\n",
    "df_data['wind'] = wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(data=df_data, case='gen_variation')\n",
    "plot_case_residual(data=df_data, case='gen_variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a dict to store the results of every approach\n",
    "approach_dict = {}\n",
    "\n",
    "for approach in approaches:\n",
    "    approach_dict[approach] = start_model(df_data, timesteps=len(df_data), plot=True, save=save_figs, case=case, \n",
    "                                          method='delay', delay_time=4, efficiency=1, approach=approach,\n",
    "                                          cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                          addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                          shed_eligibility=True, shed_time=4, n_yearLimit_shed=6,\n",
    "                                          introduce_second_dsm_unit=introduce_second_dsm_unit,\n",
    "                                          use_no_shed=use_no_shed, use_shifting_classes=use_shifting_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## More realistic data setting\n",
    "Input data from the aggregation_example.ipynb written by Julian Endres is used, see: https://github.com/windnode/SinkDSM_example/blob/master/aggregation_example.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameter settings\n",
    "* Determine model settings (timesteps)\n",
    "* Only consider project methods (other example covering different aggregation levels is not considered here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'realistic'\n",
    "\n",
    "project = 'methods'\n",
    "start_model = '2013-03-01 00:00:00+0100'\n",
    "\n",
    "# Set time range for model (further possible values are uncommented)\n",
    "#timesteps_model = 'all'\n",
    "timesteps_model = 24 * 7\n",
    "#timesteps_model = '2013-03-03 00:00:00'\n",
    "\n",
    "# Print model start and end information\n",
    "print('Model begins at:')\n",
    "print(start_model)\n",
    "\n",
    "if timesteps_model == 'all':\n",
    "    print('covers {} timesteps'.format(timesteps_model))\n",
    "elif isinstance(timesteps_model, int):\n",
    "    print('ends after {} timesteps'.format(timesteps_model))\n",
    "elif isinstance(timesteps_model, str):\n",
    "    print('ends at: {}'.format(timesteps_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input directory and file\n",
    "input_directory = 'data/{}/'.format(project)\n",
    "input_file = 'scaled_data_2.csv'\n",
    "folder = input_directory + input_file\n",
    "filename_data = os.path.join(os.path.dirname('__file__'), folder)\n",
    "\n",
    "# Read in data and do timezone adjustments\n",
    "data = pd.read_csv(filename_data,\n",
    "                   sep=\";\",\n",
    "                   decimal=',',\n",
    "                   encoding='utf-8',\n",
    "                   parse_dates=True,\n",
    "                   date_parser=pd.to_datetime)\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "tz = 'Europe/Berlin'\n",
    "data.set_index('timestamp', inplace=True)\n",
    "data.index = pd.to_datetime(data.index, utc=True).tz_convert(tz)\n",
    "data.rename(columns={'cap_up':'Cap_up', 'cap_do': 'Cap_do'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract model results for realistic toy model\n",
    "Run method defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_model, datetimeindex, dict_meta_model = create_realistic_example(data, start_model, timesteps_model, approaches,\n",
    "                                                                         plot=True, save=save_figs, method='delay', \n",
    "                                                                         delay_time=4, efficiency=1, \n",
    "                                                                         cost_dsm_up=cost_dsm_up, cost_dsm_down_shift=cost_dsm_down_shift, cost_dsm_down_shed=cost_dsm_down_shed,\n",
    "                                                                         addition=False, recovery_time_shift=None, recovery_time_shed=4, figsize=(15,8), \n",
    "                                                                         shed_eligibility=True, shed_time=4, n_yearLimit_shed=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define presets and do data preparation for output plots\n",
    "* Define some settings in order to create another kind of visualization for demand response results.\n",
    "* Transfer the data in such a shape that it can easily be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presets\n",
    "figure_size = (15,6)\n",
    "\n",
    "# start of plot\n",
    "start = datetimeindex[0]\n",
    "\n",
    "# plotted time range\n",
    "timesteps = 24 * 3 + 3 #*31\n",
    "steps = pd.date_range(start, periods=timesteps, freq='H', tz='Europe/Berlin') # stepsize\n",
    "\n",
    "plot_style = 'normal'\n",
    "\n",
    "color=['teal','goldenrod','grey','coral','olive','orchid', 'silver', 'seagreen', 'slateblue']\n",
    "drawstyle= {'scientific':{'step':'pre','drawstyle':'steps-post'},'normal':{'step':None,'drawstyle':None }}\n",
    "ds = drawstyle[plot_style]\n",
    "\n",
    "tz = 'Europe/Berlin'\n",
    "end = steps[-1]\n",
    "\n",
    "# Show some logging info\n",
    "print('start: {}'.format(start))\n",
    "print('end:   {}'.format(end))\n",
    "print('Approaches evaluated:')\n",
    "print([keys for keys in dict_df_model.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show and plot the results\n",
    "* Show total values per approach\n",
    "* Show plots in order to visually inspect differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show total values for the timeframe considered\n",
    "dsm = pd.DataFrame()\n",
    "\n",
    "for index, df in dict_df_model.items():\n",
    "    dsm[index]  =df.abs().sum().round()\n",
    "    dsm.loc['gen_total', index] = df[['wind', 'pv', 'coal1']].sum().sum().round()\n",
    "    dsm.loc['gen_EE', index] = df[['wind', 'pv']].sum().sum().round()\n",
    "\n",
    "display(dsm.loc[['demand_el','dsm_tot','excess',\n",
    "                 'cap_up', 'cap_do',\n",
    "                 'gen_total','gen_EE',\n",
    "                 'wind', 'pv', 'coal1']].T.style.bar(axis=0 ,color='goldenrod'))\n",
    "\n",
    "if save_results:\n",
    "    name = 'results_' + case + '.csv'\n",
    "    dsm.loc[['demand_el','dsm_tot','excess',\n",
    "                 'cap_up', 'cap_do',\n",
    "                 'gen_total','gen_EE',\n",
    "                 'wind', 'pv', 'coal1']].T.to_csv('./graphics/' + name, sep=';', decimal=',')\n",
    "    print(name + ' saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['wind', 'pv', 'coal1']\n",
    "plots = len([s for s in dict_df_model.keys()])\n",
    "fig_all, ax = plt.subplots(max(plots,2),1,figsize=(15,plots*4))\n",
    "\n",
    "i=0\n",
    "keys=[]\n",
    "for _, (key, df) in enumerate(dict_df_model.items()):\n",
    "    \n",
    "    keys.append(key)\n",
    "\n",
    "    ax[i].set_title(key)\n",
    "\n",
    "    # Area plot generation\n",
    "    upper = 0\n",
    "    lower = 0\n",
    "    for gen, col in enumerate(df[column]):\n",
    "        upper += df.copy().loc[steps, col]\n",
    "        upper.name = col\n",
    "        ax[i].fill_between(steps, lower, upper, step=ds['step'], facecolor=color[gen], label=col)\n",
    "        lower = upper.copy()\n",
    "\n",
    "    # plot demand\n",
    "    ax[i] = df.loc[steps,'demand_el'].plot(ax=ax[i], drawstyle=ds['drawstyle'], style='--', color='black')\n",
    "    ax[i] = df.loc[steps,'demand_dsm'].plot(ax=ax[i], drawstyle=ds['drawstyle'], style='--', color='crimson')\n",
    "\n",
    "    # calc & plot upper capacity\n",
    "    cap_up = df.loc[steps,'demand_el'] + df.loc[steps,'cap_up']\n",
    "    cap_up.name='cap_up'\n",
    "    ax[i] = cap_up.plot(ax=ax[i], drawstyle=ds['drawstyle'], style='-.', color='green')\n",
    "\n",
    "    # calc & plot lower capacity\n",
    "    cap_down = df.loc[steps,'demand_el'] - df.loc[steps,'cap_do']\n",
    "    cap_down.name='cap_do'\n",
    "    ax[i] = cap_down.plot(ax=ax[i], drawstyle=ds['drawstyle'], style='-.', color='white')\n",
    "\n",
    "\n",
    "    ax[i] = df.loc[steps, 'dsm_acum'].plot(ax=ax[i], drawstyle='steps-post', style='-.', color='indigo')\n",
    "\n",
    "    ax[i].set_ylabel('kW')\n",
    "    ax[i].set_xticks(pd.date_range(start=start, periods=timesteps/3, freq='3H', tz=tz))\n",
    "    ax[i].xaxis.set_minor_locator(mdates.DayLocator(tz = df.index.tz))\n",
    "    ax[i].xaxis.set_minor_formatter(mdates.DateFormatter('%d.%m', tz=df.index.tz))\n",
    "    ax[i].xaxis.set_major_formatter(mdates.DateFormatter('\\n%H h', tz=df.index.tz)) \n",
    "    ax[i].xaxis.grid(True, which=\"minor\")\n",
    "    ax[i].xaxis.grid(False, which=\"major\")\n",
    "    #ax[i].set_facecolor='white'\n",
    "\n",
    "\n",
    "    i+=1\n",
    "\n",
    "handles, labels = ax[i-1].get_legend_handles_labels()\n",
    "ax[i-1].legend(labels,\n",
    "             bbox_to_anchor=(0., -.5, 1., .102),\n",
    "             loc=3, ncol=4,\n",
    "             mode=\"expand\",\n",
    "             borderaxespad=0.1,\n",
    "             facecolor='silver')\n",
    "fig_all.subplots_adjust(hspace = 0.4)\n",
    "plt.show()\n",
    "\n",
    "if save_figs:\n",
    "    name = 'realistic_example_plot.png'\n",
    "    fig_all.savefig('./graphics/' + name, bbox_inches='tight')\n",
    "    print(name + ' saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare energy on hold, capacity limits as well as activations up / down\n",
    "* Energy on hold: The amount of energy that has to be compensated by load shifts in the other direction again. &rarr; A positive value means that upwards shifts are necessary for balancing.\n",
    "* Capacity limits: The capacity available for upwards resp. downwards shifts. &rarr; Identical since this is set as an input parameter.\n",
    "* Activations in upwards / downwards direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_results_plot(dict_df_model, start, timesteps, tz, 'dsm_acum', False,\n",
    "                  figure_size, 'DR - energy on hold', 'kWh', ds['drawstyle'], color, save=save_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_results_plot(dict_df_model, start, timesteps, tz, ['cap_up', 'cap_do'], {'cap_up':False, 'cap_do': True},\n",
    "                  figure_size, 'DR - capacity limits up / down', 'kW', ds['drawstyle'], color, save=save_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_results_plot(dict_df_model, start, timesteps, tz, ['dsm_up', 'dsm_do_shift'], {'dsm_up':False, 'dsm_do_shift': True},\n",
    "                  figure_size, 'DR - activations up / down', 'kW', 'steps-post', color, save=save_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
